// Lean compiler output
// Module: Lean.Meta.Tactic.Simp.BuiltinSimprocs.BitVec
// Imports: Lean.Meta.LitValues Lean.Meta.Tactic.Simp.BuiltinSimprocs.Nat Lean.Meta.Tactic.Simp.BuiltinSimprocs.Int Init.Data.BitVec.Basic
#include <lean/lean.h>
#if defined(__clang__)
#pragma clang diagnostic ignored "-Wunused-parameter"
#pragma clang diagnostic ignored "-Wunused-label"
#elif defined(__GNUC__) && !defined(__CLANG__)
#pragma GCC diagnostic ignored "-Wunused-parameter"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif
#ifdef __cplusplus
extern "C" {
#endif
lean_object* l_BitVec_abs(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__9;
lean_object* l_Lean_Expr_const___override(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1774_(lean_object*);
static lean_object* l_BitVec_reduceGetMsb___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964_(lean_object*);
static lean_object* l_BitVec_reduceToNat___closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3834_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1722_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__4;
static lean_object* l_BitVec_reduceBitVecToFin___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGT___closed__1;
static lean_object* l_BitVec_reduceSShiftRight___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceToNat(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__3;
static lean_object* l_BitVec_reduceExtracLsb_x27___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__5;
lean_object* l_Lean_mkNatLit(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__14;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__1;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__9;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808_(lean_object*);
static lean_object* l_BitVec_reduceBitVecOfFin___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceShiftLeft___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__6;
static lean_object* l_BitVec_reduceLT___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237_(lean_object*);
static lean_object* l_BitVec_reduceAllOnes___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceNot(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_mk_empty_array_with_capacity(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceULE___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToInt(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAppend___closed__5;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceLT___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAllOnes___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__6;
static lean_object* l_BitVec_reduceSub___closed__1;
lean_object* l_Lean_Meta_getNatValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceOfInt___closed__3;
static lean_object* l_BitVec_reduceHShiftLeft___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422_(lean_object*);
static lean_object* l_BitVec_reduceHShiftRight___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceUMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceLT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1670_(lean_object*);
lean_object* l_BitVec_replicate(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceOfNat___closed__1;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694____closed__1;
lean_object* l_Lean_mkAppB(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__10;
static lean_object* l_BitVec_reduceNeg___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__2;
static lean_object* l_BitVec_reduceGetLsb___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__8;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1882_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1644_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__11;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__5;
uint8_t l_Lean_Expr_isAppOfArity(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__6;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__1;
uint8_t l_Lean_Expr_isApp(lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__8;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__8;
static lean_object* l_BitVec_reduceULE___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858____closed__1;
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__4;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__1;
static lean_object* l_BitVec_reduceBitVecOfFin___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__8;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812_(lean_object*);
lean_object* lean_array_push(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__9;
static lean_object* l_BitVec_reduceXOr___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceAdd(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720_(lean_object*);
static lean_object* l_BitVec_reduceCast___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__6;
static lean_object* l_BitVec_reduceUShiftRight___closed__1;
static lean_object* l_BitVec_reduceAppend___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceLE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744_(lean_object*);
static lean_object* l_BitVec_reduceLT___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__4;
static lean_object* l_BitVec_reduceRotateRight___closed__2;
static lean_object* l_BitVec_reduceUMod___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__11;
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1696_(lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__1;
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceReplicate___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__1;
static lean_object* l_BitVec_reduceCast___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__14;
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceOfInt___closed__1;
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___closed__3;
static lean_object* l_BitVec_reduceNot___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceGT___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceGE___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464____closed__1;
lean_object* l_Lean_Meta_Simp_evalPropStep(lean_object*, uint8_t, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__4;
lean_object* l_BitVec_extractLsb_x27___rarg(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5040_(lean_object*);
static lean_object* l_BitVec_reduceDiv___closed__3;
lean_object* l_Lean_Expr_cleanupAnnotations(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_(lean_object*);
lean_object* l_Lean_Meta_evalNat(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUMod___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAnd(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceCast___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1860_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__7;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__9;
lean_object* l_BitVec_shiftLeft(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__8;
uint8_t lean_int_dec_le(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAnd___closed__3;
lean_object* lean_nat_shiftr(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__5;
static lean_object* l_BitVec_reduceSLE___closed__1;
static lean_object* l_BitVec_reduceShiftLeftZeroExtend___closed__3;
lean_object* l_Lean_Level_ofNat(lean_object*);
lean_object* l_Lean_Expr_appArg_x21(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__12;
static lean_object* l_BitVec_reduceAbs___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__9;
lean_object* l_BitVec_smtUDiv(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceMul___closed__1;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__7;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__11;
static lean_object* l_BitVec_reduceSignExtend___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3812_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAbs(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_allOnes(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__5;
static lean_object* l_BitVec_reduceShiftLeftZeroExtend___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858____closed__1;
static lean_object* l_BitVec_reduceExtracLsb_x27___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceNot___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__5;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__1;
static lean_object* l_BitVec_reduceDiv___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceHShiftRight___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceOr___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__6;
static lean_object* l_BitVec_reduceULT___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__14;
static lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771_(lean_object*);
static lean_object* l_BitVec_reduceExtracLsb_x27___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__7;
extern lean_object* l_Lean_Meta_Simp_builtinSimprocsRef;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770_(lean_object*);
lean_object* l_BitVec_neg(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__9;
lean_object* l_Lean_Meta_getIntValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__5;
uint8_t lean_nat_dec_eq(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__4;
static lean_object* l_BitVec_reduceHShiftRight___closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1508_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBin(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__5;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1816_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__6;
lean_object* l_BitVec_ofInt(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__14;
lean_object* l_BitVec_not(lean_object*, lean_object*);
lean_object* lean_nat_to_int(lean_object*);
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3284_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5241_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceULT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_div(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceXOr___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1340_(lean_object*);
static lean_object* l_BitVec_reduceSMTSDiv___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616____closed__1;
static lean_object* l_BitVec_reduceDiv___closed__1;
static lean_object* l_BitVec_reduceZeroExtend_x27___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1748_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4773_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462_(lean_object*);
static lean_object* l_BitVec_reduceZeroExtend___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__5;
static lean_object* l_BitVec_reduceXOr___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__1;
static lean_object* l_BitVec_reduceGetMsb___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__4;
static lean_object* l_BitVec_reduceShiftLeft___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_smtSDiv(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceRotateLeft___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceULE___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__10;
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__6;
static lean_object* l_BitVec_reduceGT___closed__3;
lean_object* l_Lean_Meta_getBitVecValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_ofNat(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__12;
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2674_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486_(lean_object*);
lean_object* l_Lean_Expr_appArg(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__4;
static lean_object* l_BitVec_reduceMul___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__1;
static lean_object* l_BitVec_reduceLT___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1795_(lean_object*);
static lean_object* l_BitVec_reduceToInt___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__14;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSDiv___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNeg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceGT___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766____closed__1;
static lean_object* l_BitVec_reduceSignExtend___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGE___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_Expr_appFnCleanup(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__3;
lean_object* l_BitVec_srem(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULT___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5082_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_(lean_object*);
lean_object* l_BitVec_sdiv(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__7;
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__8;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShift___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceULT___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668____closed__1;
static lean_object* l_BitVec_reduceAppend___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420_(lean_object*);
static lean_object* l_BitVec_reduceUShiftRight___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790_(lean_object*);
static lean_object* l_BitVec_reduceBitVecOfFin___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__3;
lean_object* l_BitVec_add(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMul(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_land(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772_(lean_object*);
static lean_object* l_BitVec_reduceAnd___closed__2;
lean_object* l_Lean_Name_str___override(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceSub(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToNat___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__4;
static lean_object* l_BitVec_reduceGT___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__9;
lean_object* l_BitVec_zeroExtend(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__3;
static lean_object* l_BitVec_reduceMul___closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUnary(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSub___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1382_(lean_object*);
static lean_object* l_BitVec_reduceLE___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__13;
LEAN_EXPORT lean_object* l_BitVec_reduceDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__14;
static lean_object* l_BitVec_reduceSMTUDiv___closed__2;
static lean_object* l_BitVec_reduceZeroExtend_x27___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAppend___closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceCast___closed__2;
lean_object* l_Lean_Expr_appFn_x21(lean_object*);
static lean_object* l_BitVec_reduceLE___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__2;
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5687_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856_(lean_object*);
static lean_object* l_BitVec_reduceOfInt___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3617_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__7;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceGE___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_sshiftRight(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNot___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__3;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceGT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__4;
static lean_object* l_BitVec_reduceSLE___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__2;
lean_object* l_Lean_Meta_getFinValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
uint8_t l_BitVec_slt(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__2;
static lean_object* l_BitVec_reduceMod___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239____closed__1;
static lean_object* l_BitVec_reduceSRem___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__11;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3703_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__5;
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__6;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__1;
static lean_object* l_BitVec_reduceNot___closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832_(lean_object*);
static lean_object* l_BitVec_reduceAbs___closed__2;
static lean_object* l_BitVec_reduceOr___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__11;
lean_object* l_BitVec_append___rarg(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceCast(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__3;
lean_object* l_BitVec_rotateRight(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceGE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__14;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__8;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3046_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3574_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1424_(lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__7;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceLE___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231_(lean_object*);
static lean_object* l_BitVec_reduceMod___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceLT___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424_(lean_object*);
static lean_object* l_BitVec_reduceReplicate___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__5;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744_(lean_object*);
lean_object* lean_nat_lxor(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__4;
uint8_t l_Nat_testBit(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__8;
static lean_object* l_BitVec_reduceNot___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULE___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__2;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAnd___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__4;
static lean_object* l_BitVec_reduceAdd___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1466_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__1;
static lean_object* l_BitVec_reduceUDiv___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2860_(lean_object*);
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__6;
lean_object* l_Lean_Expr_app___override(lean_object*, lean_object*);
lean_object* lean_nat_pow(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__1;
lean_object* l_BitVec_signExtend(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__2___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922_(lean_object*);
lean_object* l_Lean_Meta_Simp_registerBuiltinSimproc(lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__5;
static lean_object* l_BitVec_reduceHShiftLeft___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceZeroExtend_x27___closed__3;
uint8_t lean_nat_dec_eq(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254_(lean_object*);
static lean_object* l_BitVec_reduceOr___closed__2;
lean_object* l_Lean_mkApp3(lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1988_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__6;
static lean_object* l_BitVec_reduceLE___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__8;
uint8_t lean_nat_dec_lt(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572____closed__1;
static lean_object* l_BitVec_reduceNeg___closed__3;
lean_object* lean_nat_mod(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__1;
lean_object* l_Lean_mkRawNatLit(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__11;
static lean_object* l_BitVec_reduceAdd___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008_(lean_object*);
static lean_object* l_BitVec_reduceSRem___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__2;
lean_object* l_Lean_Meta_Simp_registerBuiltinDSimproc(lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_Name_mkStr2(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__4;
lean_object* l_BitVec_rotateLeft(lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(lean_object*, lean_object*, uint8_t, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__5;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__4;
static lean_object* l_BitVec_reduceUDiv___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__6;
static lean_object* l_BitVec_reduceAppend___closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShift(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922____closed__1;
static lean_object* l_BitVec_reduceNeg___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__1;
static lean_object* l_BitVec_reduceBinPred___lambda__1___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToNat___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__6;
uint8_t l_Lean_Expr_isConstOf(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1298_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__2;
lean_object* l_BitVec_toInt(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__5;
lean_object* l_Int_toNat(lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488_(lean_object*);
static lean_object* l_BitVec_reduceSShiftRight___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2010_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__9;
lean_object* lean_nat_shiftl(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceXOr(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_sub(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__10;
LEAN_EXPORT lean_object* l_BitVec_reduceShift___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_mul(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__2;
static lean_object* l_BitVec_reduceSub___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSRem(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSLT___closed__2;
static lean_object* l_BitVec_reduceSMod___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__4;
lean_object* l_Lean_Meta_instantiateMVarsIfMVarApp(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__14;
LEAN_EXPORT lean_object* l_BitVec_reduceOr(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceULT___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2376_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceLE___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__15;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3660_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672____closed__1;
lean_object* l_BitVec_smod(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGE___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceNot___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__13;
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__2;
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__5;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788_(lean_object*);
static lean_object* l_BitVec_reduceSMTSDiv___closed__2;
lean_object* l_BitVec_mul(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__4;
static lean_object* l_BitVec_reduceGE___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__6;
static lean_object* l_BitVec_reduceMod___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__1;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880____closed__1;
lean_object* l_Lean_instToExprInt_mkNat(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__6;
static lean_object* l_BitVec_reduceRotateRight___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282_(lean_object*);
static lean_object* l_BitVec_reduceZeroExtend___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1924_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3768_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1550_(lean_object*);
static lean_object* l_BitVec_reduceShiftLeftZeroExtend___closed__1;
static lean_object* l_BitVec_reduceRotateLeft___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746____closed__1;
static lean_object* l_BitVec_reduceAdd___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__7;
static lean_object* l_BitVec_reduceHShiftLeft___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__3;
static lean_object* l_BitVec_reduceSLT___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__5;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1618_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__7;
static lean_object* l_BitVec_reduceSMod___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__12;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__7;
lean_object* lean_int_neg(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceCast___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__12;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1592_(lean_object*);
static lean_object* l_BitVec_reduceAllOnes___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
extern lean_object* l_Lean_Meta_Simp_builtinSEvalprocsRef;
uint8_t lean_nat_dec_le(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5490_(lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__3;
lean_object* lean_nat_add(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1235_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__12;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4159_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__7;
static lean_object* l_BitVec_reduceBitVecToFin___lambda__1___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__13;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__12;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5061_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683_(lean_object*);
static lean_object* l_BitVec_reduceReplicate___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1256_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__5;
static lean_object* l_BitVec_reduceGetLsb___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__12;
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4426_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_lor(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSDiv___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__4;
lean_object* l_BitVec_sub(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__1;
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
uint8_t l_BitVec_sle(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__3;
static lean_object* l_BitVec_reduceBitVecToFin___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__5;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1966_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__7;
static lean_object* l_BitVec_reduceSMTUDiv___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__2;
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_Lean_Meta_getBitVecValue_x3f(x_1, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_10) == 0)
{
lean_object* x_11; 
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
if (lean_obj_tag(x_11) == 0)
{
uint8_t x_12; 
x_12 = !lean_is_exclusive(x_10);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
x_13 = lean_ctor_get(x_10, 0);
lean_dec(x_13);
x_14 = lean_box(0);
lean_ctor_set(x_10, 0, x_14);
return x_10;
}
else
{
lean_object* x_15; lean_object* x_16; lean_object* x_17; 
x_15 = lean_ctor_get(x_10, 1);
lean_inc(x_15);
lean_dec(x_10);
x_16 = lean_box(0);
x_17 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_17, 0, x_16);
lean_ctor_set(x_17, 1, x_15);
return x_17;
}
}
else
{
uint8_t x_18; 
x_18 = !lean_is_exclusive(x_11);
if (x_18 == 0)
{
uint8_t x_19; 
x_19 = !lean_is_exclusive(x_10);
if (x_19 == 0)
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_20 = lean_ctor_get(x_11, 0);
x_21 = lean_ctor_get(x_10, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_20, 0);
lean_inc(x_22);
x_23 = lean_ctor_get(x_20, 1);
lean_inc(x_23);
lean_dec(x_20);
x_24 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_24, 0, x_22);
lean_ctor_set(x_24, 1, x_23);
lean_ctor_set(x_11, 0, x_24);
return x_10;
}
else
{
lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; 
x_25 = lean_ctor_get(x_11, 0);
x_26 = lean_ctor_get(x_10, 1);
lean_inc(x_26);
lean_dec(x_10);
x_27 = lean_ctor_get(x_25, 0);
lean_inc(x_27);
x_28 = lean_ctor_get(x_25, 1);
lean_inc(x_28);
lean_dec(x_25);
x_29 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_29, 0, x_27);
lean_ctor_set(x_29, 1, x_28);
lean_ctor_set(x_11, 0, x_29);
x_30 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_30, 0, x_11);
lean_ctor_set(x_30, 1, x_26);
return x_30;
}
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_31 = lean_ctor_get(x_11, 0);
lean_inc(x_31);
lean_dec(x_11);
x_32 = lean_ctor_get(x_10, 1);
lean_inc(x_32);
if (lean_is_exclusive(x_10)) {
 lean_ctor_release(x_10, 0);
 lean_ctor_release(x_10, 1);
 x_33 = x_10;
} else {
 lean_dec_ref(x_10);
 x_33 = lean_box(0);
}
x_34 = lean_ctor_get(x_31, 0);
lean_inc(x_34);
x_35 = lean_ctor_get(x_31, 1);
lean_inc(x_35);
lean_dec(x_31);
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_34);
lean_ctor_set(x_36, 1, x_35);
x_37 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_37, 0, x_36);
if (lean_is_scalar(x_33)) {
 x_38 = lean_alloc_ctor(0, 2, 0);
} else {
 x_38 = x_33;
}
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_38, 1, x_32);
return x_38;
}
}
}
else
{
uint8_t x_39; 
x_39 = !lean_is_exclusive(x_10);
if (x_39 == 0)
{
return x_10;
}
else
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_40 = lean_ctor_get(x_10, 0);
x_41 = lean_ctor_get(x_10, 1);
lean_inc(x_41);
lean_inc(x_40);
lean_dec(x_10);
x_42 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_42, 0, x_40);
lean_ctor_set(x_42, 1, x_41);
return x_42;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_fromExpr_x3f(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_box(0);
x_2 = lean_alloc_ctor(2, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("BitVec", 6);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__3() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ofNat", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceUnary___lambda__1___closed__3;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceUnary___lambda__1___closed__4;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_13);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_22 = lean_ctor_get(x_13, 0);
lean_dec(x_22);
x_23 = lean_ctor_get(x_14, 0);
lean_inc(x_23);
lean_dec(x_14);
x_24 = lean_ctor_get(x_23, 0);
lean_inc(x_24);
x_25 = lean_ctor_get(x_23, 1);
lean_inc(x_25);
lean_dec(x_23);
lean_inc(x_24);
x_26 = lean_apply_2(x_2, x_24, x_25);
x_27 = l_Lean_mkNatLit(x_24);
x_28 = l_Lean_mkNatLit(x_26);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_30 = l_Lean_mkAppB(x_29, x_27, x_28);
x_31 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_13, 0, x_31);
return x_13;
}
else
{
lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_32 = lean_ctor_get(x_13, 1);
lean_inc(x_32);
lean_dec(x_13);
x_33 = lean_ctor_get(x_14, 0);
lean_inc(x_33);
lean_dec(x_14);
x_34 = lean_ctor_get(x_33, 0);
lean_inc(x_34);
x_35 = lean_ctor_get(x_33, 1);
lean_inc(x_35);
lean_dec(x_33);
lean_inc(x_34);
x_36 = lean_apply_2(x_2, x_34, x_35);
x_37 = l_Lean_mkNatLit(x_34);
x_38 = l_Lean_mkNatLit(x_36);
x_39 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_40 = l_Lean_mkAppB(x_39, x_37, x_38);
x_41 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_41, 0, x_40);
x_42 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_42, 1, x_32);
return x_42;
}
}
}
else
{
uint8_t x_43; 
lean_dec(x_2);
x_43 = !lean_is_exclusive(x_13);
if (x_43 == 0)
{
return x_13;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_44 = lean_ctor_get(x_13, 0);
x_45 = lean_ctor_get(x_13, 1);
lean_inc(x_45);
lean_inc(x_44);
lean_dec(x_13);
x_46 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_46, 0, x_44);
lean_ctor_set(x_46, 1, x_45);
return x_46;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceUnary___lambda__1(x_4, x_3, x_16, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceUnary___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_23, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_36);
lean_dec(x_35);
lean_dec(x_23);
lean_dec(x_2);
x_39 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_39);
return x_25;
}
else
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_40 = lean_ctor_get(x_23, 1);
lean_inc(x_40);
lean_dec(x_23);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
lean_inc(x_36);
x_42 = lean_apply_3(x_2, x_36, x_40, x_41);
x_43 = l_Lean_mkNatLit(x_36);
x_44 = l_Lean_mkNatLit(x_42);
x_45 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_46 = l_Lean_mkAppB(x_45, x_43, x_44);
x_47 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_47, 0, x_46);
lean_ctor_set(x_25, 0, x_47);
return x_25;
}
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; uint8_t x_52; 
x_48 = lean_ctor_get(x_25, 1);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_26, 0);
lean_inc(x_49);
lean_dec(x_26);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_49, 0);
lean_inc(x_51);
x_52 = lean_nat_dec_eq(x_50, x_51);
lean_dec(x_51);
if (x_52 == 0)
{
lean_object* x_53; lean_object* x_54; 
lean_dec(x_50);
lean_dec(x_49);
lean_dec(x_23);
lean_dec(x_2);
x_53 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_54 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_54, 0, x_53);
lean_ctor_set(x_54, 1, x_48);
return x_54;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_55 = lean_ctor_get(x_23, 1);
lean_inc(x_55);
lean_dec(x_23);
x_56 = lean_ctor_get(x_49, 1);
lean_inc(x_56);
lean_dec(x_49);
lean_inc(x_50);
x_57 = lean_apply_3(x_2, x_50, x_55, x_56);
x_58 = l_Lean_mkNatLit(x_50);
x_59 = l_Lean_mkNatLit(x_57);
x_60 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_61 = l_Lean_mkAppB(x_60, x_58, x_59);
x_62 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_63, 0, x_62);
lean_ctor_set(x_63, 1, x_48);
return x_63;
}
}
}
}
else
{
uint8_t x_64; 
lean_dec(x_23);
lean_dec(x_2);
x_64 = !lean_is_exclusive(x_25);
if (x_64 == 0)
{
return x_25;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_65 = lean_ctor_get(x_25, 0);
x_66 = lean_ctor_get(x_25, 1);
lean_inc(x_66);
lean_inc(x_65);
lean_dec(x_25);
x_67 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_67, 0, x_65);
lean_ctor_set(x_67, 1, x_66);
return x_67;
}
}
}
}
else
{
uint8_t x_68; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_68 = !lean_is_exclusive(x_14);
if (x_68 == 0)
{
return x_14;
}
else
{
lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_69 = lean_ctor_get(x_14, 0);
x_70 = lean_ctor_get(x_14, 1);
lean_inc(x_70);
lean_inc(x_69);
lean_dec(x_14);
x_71 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
return x_71;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceBin___lambda__1(x_4, x_3, x_16, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceBin___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appFn_x21(x_1);
x_24 = l_Lean_Expr_appArg_x21(x_23);
lean_dec(x_23);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_7, x_8, x_9, x_10, x_21);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_22);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_22, 1);
lean_inc(x_37);
lean_dec(x_22);
lean_inc(x_35);
x_38 = lean_apply_3(x_2, x_36, x_35, x_37);
x_39 = l_Lean_mkNatLit(x_35);
x_40 = l_Lean_mkNatLit(x_38);
x_41 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_42 = l_Lean_mkAppB(x_41, x_39, x_40);
x_43 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_43, 0, x_42);
lean_ctor_set(x_25, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_44 = lean_ctor_get(x_25, 1);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_26, 0);
lean_inc(x_45);
lean_dec(x_26);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_22, 1);
lean_inc(x_47);
lean_dec(x_22);
lean_inc(x_45);
x_48 = lean_apply_3(x_2, x_46, x_45, x_47);
x_49 = l_Lean_mkNatLit(x_45);
x_50 = l_Lean_mkNatLit(x_48);
x_51 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_52 = l_Lean_mkAppB(x_51, x_49, x_50);
x_53 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_53, 0, x_52);
x_54 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_54, 0, x_53);
lean_ctor_set(x_54, 1, x_44);
return x_54;
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_2);
x_55 = !lean_is_exclusive(x_25);
if (x_55 == 0)
{
return x_25;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_25, 0);
x_57 = lean_ctor_get(x_25, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_25);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; uint8_t x_13; 
x_12 = lean_unsigned_to_nat(3u);
x_13 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_12);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_3);
lean_dec(x_2);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_11);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceExtend___lambda__1(x_3, x_2, x_16, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceExtend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceExtend(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
return x_12;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Bool", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("false", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetBit___lambda__1___closed__1;
x_2 = l_BitVec_reduceGetBit___lambda__1___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceGetBit___lambda__1___closed__3;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceGetBit___lambda__1___closed__4;
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__6() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("true", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetBit___lambda__1___closed__1;
x_2 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceGetBit___lambda__1___closed__7;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceGetBit___lambda__1___closed__8;
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_7, x_8, x_9, x_10, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_23, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_23, 1);
lean_inc(x_37);
lean_dec(x_23);
x_38 = lean_apply_3(x_2, x_36, x_37, x_35);
x_39 = lean_unbox(x_38);
lean_dec(x_38);
if (x_39 == 0)
{
lean_object* x_40; 
x_40 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; 
x_41 = l_BitVec_reduceGetBit___lambda__1___closed__9;
lean_ctor_set(x_25, 0, x_41);
return x_25;
}
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; uint8_t x_47; 
x_42 = lean_ctor_get(x_25, 1);
lean_inc(x_42);
lean_dec(x_25);
x_43 = lean_ctor_get(x_26, 0);
lean_inc(x_43);
lean_dec(x_26);
x_44 = lean_ctor_get(x_23, 0);
lean_inc(x_44);
x_45 = lean_ctor_get(x_23, 1);
lean_inc(x_45);
lean_dec(x_23);
x_46 = lean_apply_3(x_2, x_44, x_45, x_43);
x_47 = lean_unbox(x_46);
lean_dec(x_46);
if (x_47 == 0)
{
lean_object* x_48; lean_object* x_49; 
x_48 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_49 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_49, 0, x_48);
lean_ctor_set(x_49, 1, x_42);
return x_49;
}
else
{
lean_object* x_50; lean_object* x_51; 
x_50 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_51 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_42);
return x_51;
}
}
}
}
else
{
uint8_t x_52; 
lean_dec(x_23);
lean_dec(x_2);
x_52 = !lean_is_exclusive(x_25);
if (x_52 == 0)
{
return x_25;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_53 = lean_ctor_get(x_25, 0);
x_54 = lean_ctor_get(x_25, 1);
lean_inc(x_54);
lean_inc(x_53);
lean_dec(x_25);
x_55 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_55, 0, x_53);
lean_ctor_set(x_55, 1, x_54);
return x_55;
}
}
}
}
else
{
uint8_t x_56; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_56 = !lean_is_exclusive(x_14);
if (x_56 == 0)
{
return x_14;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_57 = lean_ctor_get(x_14, 0);
x_58 = lean_ctor_get(x_14, 1);
lean_inc(x_58);
lean_inc(x_57);
lean_dec(x_14);
x_59 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_59, 0, x_57);
lean_ctor_set(x_59, 1, x_58);
return x_59;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; uint8_t x_13; 
x_12 = lean_unsigned_to_nat(3u);
x_13 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_12);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_3);
lean_dec(x_2);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_11);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceGetBit___lambda__1(x_3, x_2, x_16, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceGetBit___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceGetBit(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_7, x_8, x_9, x_10, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_23, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_23, 1);
lean_inc(x_37);
lean_dec(x_23);
lean_inc(x_36);
x_38 = lean_apply_3(x_2, x_36, x_37, x_35);
x_39 = l_Lean_mkNatLit(x_36);
x_40 = l_Lean_mkNatLit(x_38);
x_41 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_42 = l_Lean_mkAppB(x_41, x_39, x_40);
x_43 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_43, 0, x_42);
lean_ctor_set(x_25, 0, x_43);
return x_25;
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_44 = lean_ctor_get(x_25, 1);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_26, 0);
lean_inc(x_45);
lean_dec(x_26);
x_46 = lean_ctor_get(x_23, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_23, 1);
lean_inc(x_47);
lean_dec(x_23);
lean_inc(x_46);
x_48 = lean_apply_3(x_2, x_46, x_47, x_45);
x_49 = l_Lean_mkNatLit(x_46);
x_50 = l_Lean_mkNatLit(x_48);
x_51 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_52 = l_Lean_mkAppB(x_51, x_49, x_50);
x_53 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_53, 0, x_52);
x_54 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_54, 0, x_53);
lean_ctor_set(x_54, 1, x_44);
return x_54;
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_23);
lean_dec(x_2);
x_55 = !lean_is_exclusive(x_25);
if (x_55 == 0)
{
return x_25;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_25, 0);
x_57 = lean_ctor_get(x_25, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_25);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_14);
if (x_59 == 0)
{
return x_14;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_14, 0);
x_61 = lean_ctor_get(x_14, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_14);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceShift___lambda__1(x_4, x_3, x_16, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceShift___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
static lean_object* _init_l_BitVec_reduceBinPred___lambda__1___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_box(0);
x_2 = lean_alloc_ctor(2, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
lean_dec(x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_40 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; lean_object* x_45; 
lean_free_object(x_25);
x_41 = lean_ctor_get(x_23, 1);
lean_inc(x_41);
lean_dec(x_23);
x_42 = lean_ctor_get(x_36, 1);
lean_inc(x_42);
lean_dec(x_36);
x_43 = lean_apply_3(x_2, x_37, x_41, x_42);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
x_45 = l_Lean_Meta_Simp_evalPropStep(x_1, x_44, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
return x_45;
}
}
else
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; uint8_t x_50; 
x_46 = lean_ctor_get(x_25, 1);
lean_inc(x_46);
lean_dec(x_25);
x_47 = lean_ctor_get(x_26, 0);
lean_inc(x_47);
lean_dec(x_26);
x_48 = lean_ctor_get(x_23, 0);
lean_inc(x_48);
x_49 = lean_ctor_get(x_47, 0);
lean_inc(x_49);
x_50 = lean_nat_dec_eq(x_48, x_49);
lean_dec(x_49);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; 
lean_dec(x_48);
lean_dec(x_47);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_51 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_46);
return x_52;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; uint8_t x_56; lean_object* x_57; 
x_53 = lean_ctor_get(x_23, 1);
lean_inc(x_53);
lean_dec(x_23);
x_54 = lean_ctor_get(x_47, 1);
lean_inc(x_54);
lean_dec(x_47);
x_55 = lean_apply_3(x_2, x_48, x_53, x_54);
x_56 = lean_unbox(x_55);
lean_dec(x_55);
x_57 = l_Lean_Meta_Simp_evalPropStep(x_1, x_56, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_46);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_25);
if (x_58 == 0)
{
return x_25;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_25, 0);
x_60 = lean_ctor_get(x_25, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_25);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_14);
if (x_62 == 0)
{
return x_14;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_14, 0);
x_64 = lean_ctor_get(x_14, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_14);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_14 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceBinPred___lambda__1(x_4, x_3, x_16, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceBinPred___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_23, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_36);
lean_dec(x_35);
lean_dec(x_23);
lean_dec(x_2);
x_39 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_39);
return x_25;
}
else
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; uint8_t x_43; 
x_40 = lean_ctor_get(x_23, 1);
lean_inc(x_40);
lean_dec(x_23);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_apply_3(x_2, x_36, x_40, x_41);
x_43 = lean_unbox(x_42);
lean_dec(x_42);
if (x_43 == 0)
{
lean_object* x_44; 
x_44 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_25, 0, x_44);
return x_25;
}
else
{
lean_object* x_45; 
x_45 = l_BitVec_reduceGetBit___lambda__1___closed__9;
lean_ctor_set(x_25, 0, x_45);
return x_25;
}
}
}
else
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; uint8_t x_50; 
x_46 = lean_ctor_get(x_25, 1);
lean_inc(x_46);
lean_dec(x_25);
x_47 = lean_ctor_get(x_26, 0);
lean_inc(x_47);
lean_dec(x_26);
x_48 = lean_ctor_get(x_23, 0);
lean_inc(x_48);
x_49 = lean_ctor_get(x_47, 0);
lean_inc(x_49);
x_50 = lean_nat_dec_eq(x_48, x_49);
lean_dec(x_49);
if (x_50 == 0)
{
lean_object* x_51; lean_object* x_52; 
lean_dec(x_48);
lean_dec(x_47);
lean_dec(x_23);
lean_dec(x_2);
x_51 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_46);
return x_52;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; uint8_t x_56; 
x_53 = lean_ctor_get(x_23, 1);
lean_inc(x_53);
lean_dec(x_23);
x_54 = lean_ctor_get(x_47, 1);
lean_inc(x_54);
lean_dec(x_47);
x_55 = lean_apply_3(x_2, x_48, x_53, x_54);
x_56 = lean_unbox(x_55);
lean_dec(x_55);
if (x_56 == 0)
{
lean_object* x_57; lean_object* x_58; 
x_57 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_58 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_46);
return x_58;
}
else
{
lean_object* x_59; lean_object* x_60; 
x_59 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_60 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_60, 0, x_59);
lean_ctor_set(x_60, 1, x_46);
return x_60;
}
}
}
}
}
else
{
uint8_t x_61; 
lean_dec(x_23);
lean_dec(x_2);
x_61 = !lean_is_exclusive(x_25);
if (x_61 == 0)
{
return x_25;
}
else
{
lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_62 = lean_ctor_get(x_25, 0);
x_63 = lean_ctor_get(x_25, 1);
lean_inc(x_63);
lean_inc(x_62);
lean_dec(x_25);
x_64 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_64, 0, x_62);
lean_ctor_set(x_64, 1, x_63);
return x_64;
}
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_65 = !lean_is_exclusive(x_14);
if (x_65 == 0)
{
return x_14;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_14, 0);
x_67 = lean_ctor_get(x_14, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_14);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceBoolPred___lambda__1(x_4, x_3, x_16, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBoolPred___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceBoolPred___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_BitVec_neg(x_23, x_24);
lean_dec(x_24);
x_26 = l_Lean_mkNatLit(x_23);
x_27 = l_Lean_mkNatLit(x_25);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_29 = l_Lean_mkAppB(x_28, x_26, x_27);
x_30 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_30, 0, x_29);
lean_ctor_set(x_12, 0, x_30);
return x_12;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; 
x_31 = lean_ctor_get(x_12, 1);
lean_inc(x_31);
lean_dec(x_12);
x_32 = lean_ctor_get(x_13, 0);
lean_inc(x_32);
lean_dec(x_13);
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
x_34 = lean_ctor_get(x_32, 1);
lean_inc(x_34);
lean_dec(x_32);
x_35 = l_BitVec_neg(x_33, x_34);
lean_dec(x_34);
x_36 = l_Lean_mkNatLit(x_33);
x_37 = l_Lean_mkNatLit(x_35);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_39 = l_Lean_mkAppB(x_38, x_36, x_37);
x_40 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_40, 0, x_39);
x_41 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_41, 0, x_40);
lean_ctor_set(x_41, 1, x_31);
return x_41;
}
}
}
else
{
uint8_t x_42; 
x_42 = !lean_is_exclusive(x_12);
if (x_42 == 0)
{
return x_12;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; 
x_43 = lean_ctor_get(x_12, 0);
x_44 = lean_ctor_get(x_12, 1);
lean_inc(x_44);
lean_inc(x_43);
lean_dec(x_12);
x_45 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_45, 0, x_43);
lean_ctor_set(x_45, 1, x_44);
return x_45;
}
}
}
}
static lean_object* _init_l_BitVec_reduceNeg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Neg", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNeg___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("neg", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNeg___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNeg___closed__1;
x_2 = l_BitVec_reduceNeg___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceNeg___closed__3;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceNeg___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceNeg___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNeg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceNeg", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNeg___closed__3;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_3 = l_Lean_Name_str___override(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__4;
x_2 = lean_unsigned_to_nat(1u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(5u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__7;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__12() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceNeg___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__2;
x_3 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__11;
x_4 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__12;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__12;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2() {
_start:
{
lean_object* x_1; 
x_1 = l_Lean_Meta_Simp_builtinSimprocsRef;
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = l_Lean_Meta_Simp_builtinSEvalprocsRef;
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_BitVec_not(x_23, x_24);
lean_dec(x_24);
x_26 = l_Lean_mkNatLit(x_23);
x_27 = l_Lean_mkNatLit(x_25);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_29 = l_Lean_mkAppB(x_28, x_26, x_27);
x_30 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_30, 0, x_29);
lean_ctor_set(x_12, 0, x_30);
return x_12;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; 
x_31 = lean_ctor_get(x_12, 1);
lean_inc(x_31);
lean_dec(x_12);
x_32 = lean_ctor_get(x_13, 0);
lean_inc(x_32);
lean_dec(x_13);
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
x_34 = lean_ctor_get(x_32, 1);
lean_inc(x_34);
lean_dec(x_32);
x_35 = l_BitVec_not(x_33, x_34);
lean_dec(x_34);
x_36 = l_Lean_mkNatLit(x_33);
x_37 = l_Lean_mkNatLit(x_35);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_39 = l_Lean_mkAppB(x_38, x_36, x_37);
x_40 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_40, 0, x_39);
x_41 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_41, 0, x_40);
lean_ctor_set(x_41, 1, x_31);
return x_41;
}
}
}
else
{
uint8_t x_42; 
x_42 = !lean_is_exclusive(x_12);
if (x_42 == 0)
{
return x_12;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; 
x_43 = lean_ctor_get(x_12, 0);
x_44 = lean_ctor_get(x_12, 1);
lean_inc(x_44);
lean_inc(x_43);
lean_dec(x_12);
x_45 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_45, 0, x_43);
lean_ctor_set(x_45, 1, x_44);
return x_45;
}
}
}
}
static lean_object* _init_l_BitVec_reduceNot___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Complement", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNot___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("complement", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNot___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNot___closed__1;
x_2 = l_BitVec_reduceNot___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceNot___closed__3;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceNot___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceNot___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNot(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceNot", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNot___closed__3;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceNot___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__2;
x_3 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__8;
x_4 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__9;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1235_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_BitVec_abs(x_23, x_24);
lean_dec(x_24);
x_26 = l_Lean_mkNatLit(x_23);
x_27 = l_Lean_mkNatLit(x_25);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_29 = l_Lean_mkAppB(x_28, x_26, x_27);
x_30 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_30, 0, x_29);
lean_ctor_set(x_12, 0, x_30);
return x_12;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; 
x_31 = lean_ctor_get(x_12, 1);
lean_inc(x_31);
lean_dec(x_12);
x_32 = lean_ctor_get(x_13, 0);
lean_inc(x_32);
lean_dec(x_13);
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
x_34 = lean_ctor_get(x_32, 1);
lean_inc(x_34);
lean_dec(x_32);
x_35 = l_BitVec_abs(x_33, x_34);
lean_dec(x_34);
x_36 = l_Lean_mkNatLit(x_33);
x_37 = l_Lean_mkNatLit(x_35);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_39 = l_Lean_mkAppB(x_38, x_36, x_37);
x_40 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_40, 0, x_39);
x_41 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_41, 0, x_40);
lean_ctor_set(x_41, 1, x_31);
return x_41;
}
}
}
else
{
uint8_t x_42; 
x_42 = !lean_is_exclusive(x_12);
if (x_42 == 0)
{
return x_12;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; 
x_43 = lean_ctor_get(x_12, 0);
x_44 = lean_ctor_get(x_12, 1);
lean_inc(x_44);
lean_inc(x_43);
lean_dec(x_12);
x_45 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_45, 0, x_43);
lean_ctor_set(x_45, 1, x_44);
return x_45;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAbs___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("abs", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAbs___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceAbs___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceAbs___closed__2;
x_11 = lean_unsigned_to_nat(2u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceAbs___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceAbs___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAbs(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAbs", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAbs___closed__2;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAbs___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__7;
x_4 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1256_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_land(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = lean_nat_land(x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAnd___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HAnd", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAnd___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hAnd", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAnd___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAnd___closed__1;
x_2 = l_BitVec_reduceAnd___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceAnd___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceAnd___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceAnd___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAnd", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAnd___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(10u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__5;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__7;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__9;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__14() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__13;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__15() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAnd), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__14;
x_4 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__15;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__15;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1298_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_lor(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = lean_nat_lor(x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceOr___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HOr", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOr___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hOr", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOr___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceOr___closed__1;
x_2 = l_BitVec_reduceOr___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceOr___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceOr___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceOr___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceOr", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceOr___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
x_2 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOr), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__13;
x_4 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__14;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1340_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_lxor(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = lean_nat_lxor(x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceXOr___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HXor", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceXOr___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hXor", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceXOr___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceXOr___closed__1;
x_2 = l_BitVec_reduceXOr___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceXOr___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceXOr___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceXOr___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceXOr", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceXOr___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
x_2 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceXOr), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__2;
x_3 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__13;
x_4 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__14;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1382_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_add(x_35, x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = l_BitVec_add(x_49, x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAdd___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HAdd", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAdd___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hAdd", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAdd___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAdd___closed__1;
x_2 = l_BitVec_reduceAdd___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceAdd___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceAdd___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceAdd___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAdd", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAdd___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAdd), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__13;
x_4 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__14;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1424_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_mul(x_35, x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = l_BitVec_mul(x_49, x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceMul___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HMul", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMul___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hMul", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMul___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMul___closed__1;
x_2 = l_BitVec_reduceMul___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceMul___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceMul___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceMul___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceMul", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMul___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
x_2 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceMul), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__2;
x_3 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__13;
x_4 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__14;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1466_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_sub(x_35, x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = l_BitVec_sub(x_49, x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSub___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HSub", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSub___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hSub", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSub___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSub___closed__1;
x_2 = l_BitVec_reduceSub___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSub___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSub___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSub___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSub", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSub___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSub), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__13;
x_4 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__14;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1508_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_div(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = lean_nat_div(x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HDiv", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceDiv___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hDiv", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceDiv___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceDiv___closed__1;
x_2 = l_BitVec_reduceDiv___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceDiv___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceDiv___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceDiv___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceDiv", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceDiv___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
x_2 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__2;
x_3 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__13;
x_4 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__14;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1550_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_mod(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = lean_nat_mod(x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceMod___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HMod", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMod___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hMod", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMod___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMod___closed__1;
x_2 = l_BitVec_reduceMod___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceMod___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceMod___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceMod___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceMod", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMod___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4;
x_2 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceMod), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__2;
x_3 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__13;
x_4 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__14;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1592_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceUMod___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("umod", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUMod___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceUMod___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceUMod___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceMod___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUMod(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceUMod", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUMod___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUMod___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__8;
x_4 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__9;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1618_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceUDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("udiv", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUDiv___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceUDiv___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceUDiv___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceDiv___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceUDiv(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceUDiv", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUDiv___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUDiv___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__7;
x_4 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1644_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_smtUDiv(x_35, x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = l_BitVec_smtUDiv(x_49, x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSMTUDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("smtUDiv", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMTUDiv___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSMTUDiv___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSMTUDiv___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSMTUDiv___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSMTUDiv___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSMTUDiv", 13);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMTUDiv___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMTUDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1670_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_smod(x_35, x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = l_BitVec_smod(x_49, x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSMod___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("smod", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMod___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSMod___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSMod___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSMod___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSMod___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSMod", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMod___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMod), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1696_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_srem(x_35, x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = l_BitVec_srem(x_49, x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSRem___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("srem", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSRem___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSRem___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSRem___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSRem___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSRem___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSRem", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSRem___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSRem), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1722_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_sdiv(x_35, x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = l_BitVec_sdiv(x_49, x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("sdiv", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSDiv___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSDiv___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSDiv___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSDiv___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSDiv___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSDiv", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSDiv___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1748_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_smtSDiv(x_35, x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
x_42 = l_Lean_mkNatLit(x_35);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_48, 0);
lean_inc(x_50);
x_51 = lean_nat_dec_eq(x_49, x_50);
lean_dec(x_50);
if (x_51 == 0)
{
lean_object* x_52; lean_object* x_53; 
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_22);
x_52 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_47);
return x_53;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_54 = lean_ctor_get(x_22, 1);
lean_inc(x_54);
lean_dec(x_22);
x_55 = lean_ctor_get(x_48, 1);
lean_inc(x_55);
lean_dec(x_48);
x_56 = l_BitVec_smtSDiv(x_49, x_54, x_55);
lean_dec(x_55);
lean_dec(x_54);
x_57 = l_Lean_mkNatLit(x_49);
x_58 = l_Lean_mkNatLit(x_56);
x_59 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_60 = l_Lean_mkAppB(x_59, x_57, x_58);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_47);
return x_62;
}
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
x_63 = !lean_is_exclusive(x_24);
if (x_63 == 0)
{
return x_24;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_24, 0);
x_65 = lean_ctor_get(x_24, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_24);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSMTSDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("smtSDiv", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMTSDiv___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSMTSDiv___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSMTSDiv___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSMTSDiv___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSMTSDiv___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSMTSDiv", 13);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMTSDiv___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMTSDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1774_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; uint8_t x_36; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 1);
lean_inc(x_35);
lean_dec(x_22);
x_36 = l_Nat_testBit(x_35, x_34);
lean_dec(x_34);
lean_dec(x_35);
if (x_36 == 0)
{
lean_object* x_37; 
x_37 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_24, 0, x_37);
return x_24;
}
else
{
lean_object* x_38; 
x_38 = l_BitVec_reduceGetBit___lambda__1___closed__9;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_39 = lean_ctor_get(x_24, 1);
lean_inc(x_39);
lean_dec(x_24);
x_40 = lean_ctor_get(x_25, 0);
lean_inc(x_40);
lean_dec(x_25);
x_41 = lean_ctor_get(x_22, 1);
lean_inc(x_41);
lean_dec(x_22);
x_42 = l_Nat_testBit(x_41, x_40);
lean_dec(x_40);
lean_dec(x_41);
if (x_42 == 0)
{
lean_object* x_43; lean_object* x_44; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_44 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_44, 0, x_43);
lean_ctor_set(x_44, 1, x_39);
return x_44;
}
else
{
lean_object* x_45; lean_object* x_46; 
x_45 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_46 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_46, 1, x_39);
return x_46;
}
}
}
}
else
{
uint8_t x_47; 
lean_dec(x_22);
x_47 = !lean_is_exclusive(x_24);
if (x_47 == 0)
{
return x_24;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_24, 0);
x_49 = lean_ctor_get(x_24, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_24);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
}
else
{
uint8_t x_51; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_51 = !lean_is_exclusive(x_13);
if (x_51 == 0)
{
return x_13;
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_52 = lean_ctor_get(x_13, 0);
x_53 = lean_ctor_get(x_13, 1);
lean_inc(x_53);
lean_inc(x_52);
lean_dec(x_13);
x_54 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_54, 0, x_52);
lean_ctor_set(x_54, 1, x_53);
return x_54;
}
}
}
}
static lean_object* _init_l_BitVec_reduceGetLsb___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("getLsb", 6);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetLsb___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceGetLsb___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceGetLsb___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceGetLsb___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceGetLsb___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceGetLsb", 12);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetLsb___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGetLsb), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__2;
x_3 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__7;
x_4 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1795_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = lean_nat_dec_lt(x_34, x_35);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_36);
lean_dec(x_35);
lean_dec(x_34);
x_38 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_39 = lean_unsigned_to_nat(1u);
x_40 = lean_nat_sub(x_35, x_39);
lean_dec(x_35);
x_41 = lean_nat_sub(x_40, x_34);
lean_dec(x_34);
lean_dec(x_40);
x_42 = l_Nat_testBit(x_36, x_41);
lean_dec(x_41);
lean_dec(x_36);
if (x_42 == 0)
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
else
{
lean_object* x_44; 
x_44 = l_BitVec_reduceGetBit___lambda__1___closed__9;
lean_ctor_set(x_24, 0, x_44);
return x_24;
}
}
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; uint8_t x_49; 
x_45 = lean_ctor_get(x_24, 1);
lean_inc(x_45);
lean_dec(x_24);
x_46 = lean_ctor_get(x_25, 0);
lean_inc(x_46);
lean_dec(x_25);
x_47 = lean_ctor_get(x_22, 0);
lean_inc(x_47);
x_48 = lean_ctor_get(x_22, 1);
lean_inc(x_48);
lean_dec(x_22);
x_49 = lean_nat_dec_lt(x_46, x_47);
if (x_49 == 0)
{
lean_object* x_50; lean_object* x_51; 
lean_dec(x_48);
lean_dec(x_47);
lean_dec(x_46);
x_50 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_51 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_45);
return x_51;
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; uint8_t x_55; 
x_52 = lean_unsigned_to_nat(1u);
x_53 = lean_nat_sub(x_47, x_52);
lean_dec(x_47);
x_54 = lean_nat_sub(x_53, x_46);
lean_dec(x_46);
lean_dec(x_53);
x_55 = l_Nat_testBit(x_48, x_54);
lean_dec(x_54);
lean_dec(x_48);
if (x_55 == 0)
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_45);
return x_57;
}
else
{
lean_object* x_58; lean_object* x_59; 
x_58 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_59 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_59, 0, x_58);
lean_ctor_set(x_59, 1, x_45);
return x_59;
}
}
}
}
}
else
{
uint8_t x_60; 
lean_dec(x_22);
x_60 = !lean_is_exclusive(x_24);
if (x_60 == 0)
{
return x_24;
}
else
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_61 = lean_ctor_get(x_24, 0);
x_62 = lean_ctor_get(x_24, 1);
lean_inc(x_62);
lean_inc(x_61);
lean_dec(x_24);
x_63 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_63, 0, x_61);
lean_ctor_set(x_63, 1, x_62);
return x_63;
}
}
}
}
else
{
uint8_t x_64; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_64 = !lean_is_exclusive(x_13);
if (x_64 == 0)
{
return x_13;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_65 = lean_ctor_get(x_13, 0);
x_66 = lean_ctor_get(x_13, 1);
lean_inc(x_66);
lean_inc(x_65);
lean_dec(x_13);
x_67 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_67, 0, x_65);
lean_ctor_set(x_67, 1, x_66);
return x_67;
}
}
}
}
static lean_object* _init_l_BitVec_reduceGetMsb___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("getMsb", 6);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetMsb___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceGetMsb___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceGetMsb___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceGetMsb___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceGetMsb___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceGetMsb", 12);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetMsb___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGetMsb), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__2;
x_3 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__7;
x_4 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1816_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = l_BitVec_shiftLeft(x_35, x_36, x_34);
lean_dec(x_34);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_43 = lean_ctor_get(x_24, 1);
lean_inc(x_43);
lean_dec(x_24);
x_44 = lean_ctor_get(x_25, 0);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_22, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_22, 1);
lean_inc(x_46);
lean_dec(x_22);
x_47 = l_BitVec_shiftLeft(x_45, x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_Lean_mkNatLit(x_45);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
lean_dec(x_22);
x_54 = !lean_is_exclusive(x_24);
if (x_54 == 0)
{
return x_24;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_24, 0);
x_56 = lean_ctor_get(x_24, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_24);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_13);
if (x_58 == 0)
{
return x_13;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_13, 0);
x_60 = lean_ctor_get(x_13, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_13);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
static lean_object* _init_l_BitVec_reduceShiftLeft___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("shiftLeft", 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeft___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceShiftLeft___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceShiftLeft___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceShiftLeft___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceShiftLeft___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceShiftLeft", 15);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceShiftLeft___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeft), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__2;
x_3 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__7;
x_4 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = lean_nat_shiftr(x_36, x_34);
lean_dec(x_34);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_43 = lean_ctor_get(x_24, 1);
lean_inc(x_43);
lean_dec(x_24);
x_44 = lean_ctor_get(x_25, 0);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_22, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_22, 1);
lean_inc(x_46);
lean_dec(x_22);
x_47 = lean_nat_shiftr(x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_Lean_mkNatLit(x_45);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
lean_dec(x_22);
x_54 = !lean_is_exclusive(x_24);
if (x_54 == 0)
{
return x_24;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_24, 0);
x_56 = lean_ctor_get(x_24, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_24);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_13);
if (x_58 == 0)
{
return x_13;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_13, 0);
x_60 = lean_ctor_get(x_13, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_13);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
static lean_object* _init_l_BitVec_reduceUShiftRight___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ushiftRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUShiftRight___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceUShiftRight___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceUShiftRight___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceUShiftRight___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceUShiftRight___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceUShiftRight", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUShiftRight___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUShiftRight), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__7;
x_4 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1860_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = l_BitVec_sshiftRight(x_35, x_36, x_34);
lean_dec(x_34);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_43 = lean_ctor_get(x_24, 1);
lean_inc(x_43);
lean_dec(x_24);
x_44 = lean_ctor_get(x_25, 0);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_22, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_22, 1);
lean_inc(x_46);
lean_dec(x_22);
x_47 = l_BitVec_sshiftRight(x_45, x_46, x_44);
lean_dec(x_44);
x_48 = l_Lean_mkNatLit(x_45);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
lean_dec(x_22);
x_54 = !lean_is_exclusive(x_24);
if (x_54 == 0)
{
return x_24;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_24, 0);
x_56 = lean_ctor_get(x_24, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_24);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_13);
if (x_58 == 0)
{
return x_13;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_13, 0);
x_60 = lean_ctor_get(x_13, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_13);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSShiftRight___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("sshiftRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSShiftRight___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSShiftRight___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSShiftRight___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSShiftRight___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSShiftRight___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSShiftRight", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSShiftRight___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSShiftRight), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1882_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HShiftLeft", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hShiftLeft", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftLeft___closed__1;
x_2 = l_BitVec_reduceHShiftLeft___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceHShiftLeft___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceShiftLeft___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftLeft(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceHShiftLeft", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftLeft___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(8u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__4;
x_2 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__7;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__13() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftLeft___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__2;
x_3 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__12;
x_4 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__13;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__13;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1924_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HShiftRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hShiftRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftRight___closed__1;
x_2 = l_BitVec_reduceHShiftRight___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceHShiftRight___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceUShiftRight___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftRight(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceHShiftRight", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftRight___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__4;
x_2 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__12() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftRight___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__2;
x_3 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__11;
x_4 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__12;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__12;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1966_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = l_BitVec_rotateLeft(x_35, x_36, x_34);
lean_dec(x_34);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_43 = lean_ctor_get(x_24, 1);
lean_inc(x_43);
lean_dec(x_24);
x_44 = lean_ctor_get(x_25, 0);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_22, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_22, 1);
lean_inc(x_46);
lean_dec(x_22);
x_47 = l_BitVec_rotateLeft(x_45, x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_Lean_mkNatLit(x_45);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
lean_dec(x_22);
x_54 = !lean_is_exclusive(x_24);
if (x_54 == 0)
{
return x_24;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_24, 0);
x_56 = lean_ctor_get(x_24, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_24);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_13);
if (x_58 == 0)
{
return x_13;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_13, 0);
x_60 = lean_ctor_get(x_13, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_13);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
static lean_object* _init_l_BitVec_reduceRotateLeft___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("rotateLeft", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceRotateLeft___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceRotateLeft___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceRotateLeft___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceRotateLeft___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceRotateLeft___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceRotateLeft", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceRotateLeft___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceRotateLeft), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__2;
x_3 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__7;
x_4 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1988_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = l_BitVec_rotateRight(x_35, x_36, x_34);
lean_dec(x_34);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_43 = lean_ctor_get(x_24, 1);
lean_inc(x_43);
lean_dec(x_24);
x_44 = lean_ctor_get(x_25, 0);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_22, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_22, 1);
lean_inc(x_46);
lean_dec(x_22);
x_47 = l_BitVec_rotateRight(x_45, x_46, x_44);
lean_dec(x_44);
lean_dec(x_46);
x_48 = l_Lean_mkNatLit(x_45);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
lean_dec(x_22);
x_54 = !lean_is_exclusive(x_24);
if (x_54 == 0)
{
return x_24;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_24, 0);
x_56 = lean_ctor_get(x_24, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_24);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_13);
if (x_58 == 0)
{
return x_13;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_13, 0);
x_60 = lean_ctor_get(x_13, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_13);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
static lean_object* _init_l_BitVec_reduceRotateRight___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("rotateRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceRotateRight___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceRotateRight___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceRotateRight___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceRotateRight___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceRotateRight___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceRotateRight", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceRotateRight___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceRotateRight), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__2;
x_3 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__7;
x_4 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2010_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_11 = l_BitVec_fromExpr_x3f(x_1, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_11) == 0)
{
lean_object* x_12; 
x_12 = lean_ctor_get(x_11, 0);
lean_inc(x_12);
if (lean_obj_tag(x_12) == 0)
{
uint8_t x_13; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_2);
x_13 = !lean_is_exclusive(x_11);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
x_14 = lean_ctor_get(x_11, 0);
lean_dec(x_14);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_11, 0, x_15);
return x_11;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = lean_ctor_get(x_11, 1);
lean_inc(x_16);
lean_dec(x_11);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_18 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_18, 0, x_17);
lean_ctor_set(x_18, 1, x_16);
return x_18;
}
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_11, 1);
lean_inc(x_19);
lean_dec(x_11);
x_20 = lean_ctor_get(x_12, 0);
lean_inc(x_20);
lean_dec(x_12);
x_21 = l_BitVec_fromExpr_x3f(x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_19);
if (lean_obj_tag(x_21) == 0)
{
lean_object* x_22; 
x_22 = lean_ctor_get(x_21, 0);
lean_inc(x_22);
if (lean_obj_tag(x_22) == 0)
{
uint8_t x_23; 
lean_dec(x_20);
x_23 = !lean_is_exclusive(x_21);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; 
x_24 = lean_ctor_get(x_21, 0);
lean_dec(x_24);
x_25 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_25);
return x_21;
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_26 = lean_ctor_get(x_21, 1);
lean_inc(x_26);
lean_dec(x_21);
x_27 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_28 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_26);
return x_28;
}
}
else
{
uint8_t x_29; 
x_29 = !lean_is_exclusive(x_21);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_30 = lean_ctor_get(x_21, 0);
lean_dec(x_30);
x_31 = lean_ctor_get(x_22, 0);
lean_inc(x_31);
lean_dec(x_22);
x_32 = lean_ctor_get(x_20, 0);
lean_inc(x_32);
x_33 = lean_ctor_get(x_31, 0);
lean_inc(x_33);
x_34 = lean_nat_add(x_32, x_33);
lean_dec(x_32);
x_35 = lean_ctor_get(x_20, 1);
lean_inc(x_35);
lean_dec(x_20);
x_36 = lean_ctor_get(x_31, 1);
lean_inc(x_36);
lean_dec(x_31);
x_37 = l_BitVec_append___rarg(x_33, x_35, x_36);
lean_dec(x_36);
lean_dec(x_35);
lean_dec(x_33);
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_21, 0, x_42);
return x_21;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_43 = lean_ctor_get(x_21, 1);
lean_inc(x_43);
lean_dec(x_21);
x_44 = lean_ctor_get(x_22, 0);
lean_inc(x_44);
lean_dec(x_22);
x_45 = lean_ctor_get(x_20, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_44, 0);
lean_inc(x_46);
x_47 = lean_nat_add(x_45, x_46);
lean_dec(x_45);
x_48 = lean_ctor_get(x_20, 1);
lean_inc(x_48);
lean_dec(x_20);
x_49 = lean_ctor_get(x_44, 1);
lean_inc(x_49);
lean_dec(x_44);
x_50 = l_BitVec_append___rarg(x_46, x_48, x_49);
lean_dec(x_49);
lean_dec(x_48);
lean_dec(x_46);
x_51 = l_Lean_mkNatLit(x_47);
x_52 = l_Lean_mkNatLit(x_50);
x_53 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_54 = l_Lean_mkAppB(x_53, x_51, x_52);
x_55 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_55, 0, x_54);
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_43);
return x_56;
}
}
}
else
{
uint8_t x_57; 
lean_dec(x_20);
x_57 = !lean_is_exclusive(x_21);
if (x_57 == 0)
{
return x_21;
}
else
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_58 = lean_ctor_get(x_21, 0);
x_59 = lean_ctor_get(x_21, 1);
lean_inc(x_59);
lean_inc(x_58);
lean_dec(x_21);
x_60 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
return x_60;
}
}
}
}
else
{
uint8_t x_61; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_2);
x_61 = !lean_is_exclusive(x_11);
if (x_61 == 0)
{
return x_11;
}
else
{
lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_62 = lean_ctor_get(x_11, 0);
x_63 = lean_ctor_get(x_11, 1);
lean_inc(x_63);
lean_inc(x_62);
lean_dec(x_11);
x_64 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_64, 0, x_62);
lean_ctor_set(x_64, 1, x_63);
return x_64;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; 
x_10 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_11 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_11, 0, x_10);
lean_ctor_set(x_11, 1, x_9);
return x_11;
}
}
static lean_object* _init_l_BitVec_reduceAppend___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAppend___lambda__1___boxed), 10, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAppend___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAppend___lambda__2___boxed), 9, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAppend___closed__3() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HAppend", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAppend___closed__4() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hAppend", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAppend___closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAppend___closed__3;
x_2 = l_BitVec_reduceAppend___closed__4;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceAppend___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appArg(x_20, lean_box(0));
x_25 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_26 = l_Lean_Expr_isApp(x_25);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
lean_dec(x_25);
lean_dec(x_24);
lean_dec(x_19);
x_27 = lean_box(0);
x_28 = lean_apply_9(x_14, x_27, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_28;
}
else
{
lean_object* x_29; uint8_t x_30; 
x_29 = l_Lean_Expr_appFnCleanup(x_25, lean_box(0));
x_30 = l_Lean_Expr_isApp(x_29);
if (x_30 == 0)
{
lean_object* x_31; lean_object* x_32; 
lean_dec(x_29);
lean_dec(x_24);
lean_dec(x_19);
x_31 = lean_box(0);
x_32 = lean_apply_9(x_14, x_31, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_32;
}
else
{
lean_object* x_33; uint8_t x_34; 
x_33 = l_Lean_Expr_appFnCleanup(x_29, lean_box(0));
x_34 = l_Lean_Expr_isApp(x_33);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; 
lean_dec(x_33);
lean_dec(x_24);
lean_dec(x_19);
x_35 = lean_box(0);
x_36 = lean_apply_9(x_14, x_35, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_36;
}
else
{
lean_object* x_37; uint8_t x_38; 
x_37 = l_Lean_Expr_appFnCleanup(x_33, lean_box(0));
x_38 = l_Lean_Expr_isApp(x_37);
if (x_38 == 0)
{
lean_object* x_39; lean_object* x_40; 
lean_dec(x_37);
lean_dec(x_24);
lean_dec(x_19);
x_39 = lean_box(0);
x_40 = lean_apply_9(x_14, x_39, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_40;
}
else
{
lean_object* x_41; lean_object* x_42; uint8_t x_43; 
x_41 = l_Lean_Expr_appFnCleanup(x_37, lean_box(0));
x_42 = l_BitVec_reduceAppend___closed__5;
x_43 = l_Lean_Expr_isConstOf(x_41, x_42);
lean_dec(x_41);
if (x_43 == 0)
{
lean_object* x_44; lean_object* x_45; 
lean_dec(x_24);
lean_dec(x_19);
x_44 = lean_box(0);
x_45 = lean_apply_9(x_14, x_44, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_45;
}
else
{
lean_object* x_46; 
x_46 = lean_apply_10(x_13, x_24, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_46;
}
}
}
}
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceAppend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__2___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAppend___lambda__2(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAppend", 12);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAppend___closed__5;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__12() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAppend), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__11;
x_4 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__12;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__12;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2376_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_11 = l_BitVec_fromExpr_x3f(x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_11) == 0)
{
lean_object* x_12; 
x_12 = lean_ctor_get(x_11, 0);
lean_inc(x_12);
if (lean_obj_tag(x_12) == 0)
{
uint8_t x_13; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_13 = !lean_is_exclusive(x_11);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
x_14 = lean_ctor_get(x_11, 0);
lean_dec(x_14);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_11, 0, x_15);
return x_11;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = lean_ctor_get(x_11, 1);
lean_inc(x_16);
lean_dec(x_11);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_18 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_18, 0, x_17);
lean_ctor_set(x_18, 1, x_16);
return x_18;
}
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_11, 1);
lean_inc(x_19);
lean_dec(x_11);
x_20 = lean_ctor_get(x_12, 0);
lean_inc(x_20);
lean_dec(x_12);
x_21 = l_Lean_Meta_getNatValue_x3f(x_1, x_6, x_7, x_8, x_9, x_19);
if (lean_obj_tag(x_21) == 0)
{
lean_object* x_22; 
x_22 = lean_ctor_get(x_21, 0);
lean_inc(x_22);
if (lean_obj_tag(x_22) == 0)
{
uint8_t x_23; 
lean_dec(x_20);
x_23 = !lean_is_exclusive(x_21);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; 
x_24 = lean_ctor_get(x_21, 0);
lean_dec(x_24);
x_25 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_25);
return x_21;
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_26 = lean_ctor_get(x_21, 1);
lean_inc(x_26);
lean_dec(x_21);
x_27 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_28 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_26);
return x_28;
}
}
else
{
uint8_t x_29; 
x_29 = !lean_is_exclusive(x_21);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_30 = lean_ctor_get(x_21, 0);
lean_dec(x_30);
x_31 = lean_ctor_get(x_22, 0);
lean_inc(x_31);
lean_dec(x_22);
x_32 = lean_ctor_get(x_20, 1);
lean_inc(x_32);
lean_dec(x_20);
x_33 = l_BitVec_ofNat(x_31, x_32);
lean_dec(x_32);
x_34 = l_Lean_mkNatLit(x_31);
x_35 = l_Lean_mkNatLit(x_33);
x_36 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_37 = l_Lean_mkAppB(x_36, x_34, x_35);
x_38 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_21, 0, x_38);
return x_21;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; 
x_39 = lean_ctor_get(x_21, 1);
lean_inc(x_39);
lean_dec(x_21);
x_40 = lean_ctor_get(x_22, 0);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_20, 1);
lean_inc(x_41);
lean_dec(x_20);
x_42 = l_BitVec_ofNat(x_40, x_41);
lean_dec(x_41);
x_43 = l_Lean_mkNatLit(x_40);
x_44 = l_Lean_mkNatLit(x_42);
x_45 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_46 = l_Lean_mkAppB(x_45, x_43, x_44);
x_47 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_47, 0, x_46);
x_48 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_48, 0, x_47);
lean_ctor_set(x_48, 1, x_39);
return x_48;
}
}
}
else
{
uint8_t x_49; 
lean_dec(x_20);
x_49 = !lean_is_exclusive(x_21);
if (x_49 == 0)
{
return x_21;
}
else
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_50 = lean_ctor_get(x_21, 0);
x_51 = lean_ctor_get(x_21, 1);
lean_inc(x_51);
lean_inc(x_50);
lean_dec(x_21);
x_52 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_52, 0, x_50);
lean_ctor_set(x_52, 1, x_51);
return x_52;
}
}
}
}
else
{
uint8_t x_53; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_53 = !lean_is_exclusive(x_11);
if (x_53 == 0)
{
return x_11;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_54 = lean_ctor_get(x_11, 0);
x_55 = lean_ctor_get(x_11, 1);
lean_inc(x_55);
lean_inc(x_54);
lean_dec(x_11);
x_56 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_56, 0, x_54);
lean_ctor_set(x_56, 1, x_55);
return x_56;
}
}
}
}
static lean_object* _init_l_BitVec_reduceCast___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceCast___lambda__1___boxed), 10, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceCast___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("cast", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceCast___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceCast___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceCast___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; uint8_t x_25; 
x_24 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_25 = l_Lean_Expr_isApp(x_24);
if (x_25 == 0)
{
lean_object* x_26; lean_object* x_27; 
lean_dec(x_24);
lean_dec(x_19);
x_26 = lean_box(0);
x_27 = lean_apply_9(x_14, x_26, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_27;
}
else
{
lean_object* x_28; lean_object* x_29; uint8_t x_30; 
x_28 = l_Lean_Expr_appArg(x_24, lean_box(0));
x_29 = l_Lean_Expr_appFnCleanup(x_24, lean_box(0));
x_30 = l_Lean_Expr_isApp(x_29);
if (x_30 == 0)
{
lean_object* x_31; lean_object* x_32; 
lean_dec(x_29);
lean_dec(x_28);
lean_dec(x_19);
x_31 = lean_box(0);
x_32 = lean_apply_9(x_14, x_31, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_32;
}
else
{
lean_object* x_33; lean_object* x_34; uint8_t x_35; 
x_33 = l_Lean_Expr_appFnCleanup(x_29, lean_box(0));
x_34 = l_BitVec_reduceCast___closed__3;
x_35 = l_Lean_Expr_isConstOf(x_33, x_34);
lean_dec(x_33);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; 
lean_dec(x_28);
lean_dec(x_19);
x_36 = lean_box(0);
x_37 = lean_apply_9(x_14, x_36, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_37;
}
else
{
lean_object* x_38; 
x_38 = lean_apply_10(x_13, x_28, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_38;
}
}
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceCast___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceCast", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceCast___closed__3;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6;
x_2 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceCast), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__2;
x_3 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__8;
x_4 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__9;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2674_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_fromExpr_x3f(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_10) == 0)
{
lean_object* x_11; 
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
if (lean_obj_tag(x_11) == 0)
{
uint8_t x_12; 
x_12 = !lean_is_exclusive(x_10);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
x_13 = lean_ctor_get(x_10, 0);
lean_dec(x_13);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_10, 0, x_14);
return x_10;
}
else
{
lean_object* x_15; lean_object* x_16; lean_object* x_17; 
x_15 = lean_ctor_get(x_10, 1);
lean_inc(x_15);
lean_dec(x_10);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_17 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_17, 0, x_16);
lean_ctor_set(x_17, 1, x_15);
return x_17;
}
}
else
{
uint8_t x_18; 
x_18 = !lean_is_exclusive(x_10);
if (x_18 == 0)
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; 
x_19 = lean_ctor_get(x_10, 0);
lean_dec(x_19);
x_20 = lean_ctor_get(x_11, 0);
lean_inc(x_20);
lean_dec(x_11);
x_21 = lean_ctor_get(x_20, 1);
lean_inc(x_21);
lean_dec(x_20);
x_22 = l_Lean_mkNatLit(x_21);
x_23 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_23, 0, x_22);
lean_ctor_set(x_10, 0, x_23);
return x_10;
}
else
{
lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_24 = lean_ctor_get(x_10, 1);
lean_inc(x_24);
lean_dec(x_10);
x_25 = lean_ctor_get(x_11, 0);
lean_inc(x_25);
lean_dec(x_11);
x_26 = lean_ctor_get(x_25, 1);
lean_inc(x_26);
lean_dec(x_25);
x_27 = l_Lean_mkNatLit(x_26);
x_28 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_28, 0, x_27);
x_29 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_29, 0, x_28);
lean_ctor_set(x_29, 1, x_24);
return x_29;
}
}
}
else
{
uint8_t x_30; 
x_30 = !lean_is_exclusive(x_10);
if (x_30 == 0)
{
return x_10;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_10, 0);
x_32 = lean_ctor_get(x_10, 1);
lean_inc(x_32);
lean_inc(x_31);
lean_dec(x_10);
x_33 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_33, 0, x_31);
lean_ctor_set(x_33, 1, x_32);
return x_33;
}
}
}
}
static lean_object* _init_l_BitVec_reduceToNat___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceToNat___lambda__1___boxed), 9, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToNat___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("toNat", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToNat___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceToNat___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceToNat___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_25 = l_BitVec_reduceToNat___closed__3;
x_26 = l_Lean_Expr_isConstOf(x_24, x_25);
lean_dec(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
lean_dec(x_19);
x_27 = lean_box(0);
x_28 = lean_apply_9(x_14, x_27, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_28;
}
else
{
lean_object* x_29; 
x_29 = lean_apply_9(x_13, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_29;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceToNat___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceToNat", 11);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToNat___closed__3;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4;
x_2 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceToNat), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__2;
x_3 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__6;
x_4 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__7;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2860_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(0u);
x_2 = lean_nat_to_int(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(0u);
x_2 = l_Lean_Level_ofNat(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___lambda__1___closed__2;
x_3 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNeg___closed__3;
x_2 = l_BitVec_reduceToInt___lambda__1___closed__3;
x_3 = l_Lean_Expr_const___override(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__5() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Int", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___lambda__1___closed__5;
x_3 = l_Lean_Name_str___override(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___lambda__1___closed__6;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("instNegInt", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToInt___lambda__1___closed__5;
x_2 = l_BitVec_reduceToInt___lambda__1___closed__8;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___lambda__1___closed__9;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_fromExpr_x3f(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_10) == 0)
{
lean_object* x_11; 
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
if (lean_obj_tag(x_11) == 0)
{
uint8_t x_12; 
x_12 = !lean_is_exclusive(x_10);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
x_13 = lean_ctor_get(x_10, 0);
lean_dec(x_13);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_10, 0, x_14);
return x_10;
}
else
{
lean_object* x_15; lean_object* x_16; lean_object* x_17; 
x_15 = lean_ctor_get(x_10, 1);
lean_inc(x_15);
lean_dec(x_10);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_17 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_17, 0, x_16);
lean_ctor_set(x_17, 1, x_15);
return x_17;
}
}
else
{
uint8_t x_18; 
x_18 = !lean_is_exclusive(x_10);
if (x_18 == 0)
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; uint8_t x_25; 
x_19 = lean_ctor_get(x_10, 0);
lean_dec(x_19);
x_20 = lean_ctor_get(x_11, 0);
lean_inc(x_20);
lean_dec(x_11);
x_21 = lean_ctor_get(x_20, 0);
lean_inc(x_21);
x_22 = lean_ctor_get(x_20, 1);
lean_inc(x_22);
lean_dec(x_20);
x_23 = l_BitVec_toInt(x_21, x_22);
lean_dec(x_21);
x_24 = l_BitVec_reduceToInt___lambda__1___closed__1;
x_25 = lean_int_dec_le(x_24, x_23);
if (x_25 == 0)
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_26 = lean_int_neg(x_23);
lean_dec(x_23);
x_27 = l_Int_toNat(x_26);
lean_dec(x_26);
x_28 = l_Lean_instToExprInt_mkNat(x_27);
x_29 = l_BitVec_reduceToInt___lambda__1___closed__4;
x_30 = l_BitVec_reduceToInt___lambda__1___closed__7;
x_31 = l_BitVec_reduceToInt___lambda__1___closed__10;
x_32 = l_Lean_mkApp3(x_29, x_30, x_31, x_28);
x_33 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_33, 0, x_32);
lean_ctor_set(x_10, 0, x_33);
return x_10;
}
else
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_34 = l_Int_toNat(x_23);
lean_dec(x_23);
x_35 = l_Lean_instToExprInt_mkNat(x_34);
x_36 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_36, 0, x_35);
lean_ctor_set(x_10, 0, x_36);
return x_10;
}
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint8_t x_43; 
x_37 = lean_ctor_get(x_10, 1);
lean_inc(x_37);
lean_dec(x_10);
x_38 = lean_ctor_get(x_11, 0);
lean_inc(x_38);
lean_dec(x_11);
x_39 = lean_ctor_get(x_38, 0);
lean_inc(x_39);
x_40 = lean_ctor_get(x_38, 1);
lean_inc(x_40);
lean_dec(x_38);
x_41 = l_BitVec_toInt(x_39, x_40);
lean_dec(x_39);
x_42 = l_BitVec_reduceToInt___lambda__1___closed__1;
x_43 = lean_int_dec_le(x_42, x_41);
if (x_43 == 0)
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_44 = lean_int_neg(x_41);
lean_dec(x_41);
x_45 = l_Int_toNat(x_44);
lean_dec(x_44);
x_46 = l_Lean_instToExprInt_mkNat(x_45);
x_47 = l_BitVec_reduceToInt___lambda__1___closed__4;
x_48 = l_BitVec_reduceToInt___lambda__1___closed__7;
x_49 = l_BitVec_reduceToInt___lambda__1___closed__10;
x_50 = l_Lean_mkApp3(x_47, x_48, x_49, x_46);
x_51 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_51, 0, x_50);
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_37);
return x_52;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_53 = l_Int_toNat(x_41);
lean_dec(x_41);
x_54 = l_Lean_instToExprInt_mkNat(x_53);
x_55 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_55, 0, x_54);
x_56 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_56, 0, x_55);
lean_ctor_set(x_56, 1, x_37);
return x_56;
}
}
}
}
else
{
uint8_t x_57; 
x_57 = !lean_is_exclusive(x_10);
if (x_57 == 0)
{
return x_10;
}
else
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_58 = lean_ctor_get(x_10, 0);
x_59 = lean_ctor_get(x_10, 1);
lean_inc(x_59);
lean_inc(x_58);
lean_dec(x_10);
x_60 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
return x_60;
}
}
}
}
static lean_object* _init_l_BitVec_reduceToInt___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceToInt___lambda__1___boxed), 9, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("toInt", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceToInt___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceToInt___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_25 = l_BitVec_reduceToInt___closed__3;
x_26 = l_Lean_Expr_isConstOf(x_24, x_25);
lean_dec(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
lean_dec(x_19);
x_27 = lean_box(0);
x_28 = lean_apply_9(x_14, x_27, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_28;
}
else
{
lean_object* x_29; 
x_29 = lean_apply_9(x_13, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_29;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceToInt___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceToInt", 11);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToInt___closed__3;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4;
x_2 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceToInt), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__2;
x_3 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__6;
x_4 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__7;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3046_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_11 = l_Lean_Meta_getNatValue_x3f(x_1, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_11) == 0)
{
lean_object* x_12; 
x_12 = lean_ctor_get(x_11, 0);
lean_inc(x_12);
if (lean_obj_tag(x_12) == 0)
{
uint8_t x_13; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_2);
x_13 = !lean_is_exclusive(x_11);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
x_14 = lean_ctor_get(x_11, 0);
lean_dec(x_14);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_11, 0, x_15);
return x_11;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = lean_ctor_get(x_11, 1);
lean_inc(x_16);
lean_dec(x_11);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_18 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_18, 0, x_17);
lean_ctor_set(x_18, 1, x_16);
return x_18;
}
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_11, 1);
lean_inc(x_19);
lean_dec(x_11);
x_20 = lean_ctor_get(x_12, 0);
lean_inc(x_20);
lean_dec(x_12);
x_21 = l_Lean_Meta_getIntValue_x3f(x_2, x_6, x_7, x_8, x_9, x_19);
if (lean_obj_tag(x_21) == 0)
{
lean_object* x_22; 
x_22 = lean_ctor_get(x_21, 0);
lean_inc(x_22);
if (lean_obj_tag(x_22) == 0)
{
uint8_t x_23; 
lean_dec(x_20);
x_23 = !lean_is_exclusive(x_21);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; 
x_24 = lean_ctor_get(x_21, 0);
lean_dec(x_24);
x_25 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_25);
return x_21;
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_26 = lean_ctor_get(x_21, 1);
lean_inc(x_26);
lean_dec(x_21);
x_27 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_28 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_26);
return x_28;
}
}
else
{
uint8_t x_29; 
x_29 = !lean_is_exclusive(x_21);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; 
x_30 = lean_ctor_get(x_21, 0);
lean_dec(x_30);
x_31 = lean_ctor_get(x_22, 0);
lean_inc(x_31);
lean_dec(x_22);
x_32 = l_BitVec_ofInt(x_20, x_31);
lean_dec(x_31);
x_33 = l_Lean_mkNatLit(x_20);
x_34 = l_Lean_mkNatLit(x_32);
x_35 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_36 = l_Lean_mkAppB(x_35, x_33, x_34);
x_37 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_37, 0, x_36);
lean_ctor_set(x_21, 0, x_37);
return x_21;
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; 
x_38 = lean_ctor_get(x_21, 1);
lean_inc(x_38);
lean_dec(x_21);
x_39 = lean_ctor_get(x_22, 0);
lean_inc(x_39);
lean_dec(x_22);
x_40 = l_BitVec_ofInt(x_20, x_39);
lean_dec(x_39);
x_41 = l_Lean_mkNatLit(x_20);
x_42 = l_Lean_mkNatLit(x_40);
x_43 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_44 = l_Lean_mkAppB(x_43, x_41, x_42);
x_45 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_45, 0, x_44);
x_46 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_46, 1, x_38);
return x_46;
}
}
}
else
{
uint8_t x_47; 
lean_dec(x_20);
x_47 = !lean_is_exclusive(x_21);
if (x_47 == 0)
{
return x_21;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_21, 0);
x_49 = lean_ctor_get(x_21, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_21);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
}
else
{
uint8_t x_51; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_2);
x_51 = !lean_is_exclusive(x_11);
if (x_51 == 0)
{
return x_11;
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_52 = lean_ctor_get(x_11, 0);
x_53 = lean_ctor_get(x_11, 1);
lean_inc(x_53);
lean_inc(x_52);
lean_dec(x_11);
x_54 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_54, 0, x_52);
lean_ctor_set(x_54, 1, x_53);
return x_54;
}
}
}
}
static lean_object* _init_l_BitVec_reduceOfInt___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOfInt___lambda__1___boxed), 10, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOfInt___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ofInt", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOfInt___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceOfInt___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceOfInt___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; lean_object* x_26; uint8_t x_27; 
x_24 = l_Lean_Expr_appArg(x_20, lean_box(0));
x_25 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_26 = l_BitVec_reduceOfInt___closed__3;
x_27 = l_Lean_Expr_isConstOf(x_25, x_26);
lean_dec(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
lean_dec(x_24);
lean_dec(x_19);
x_28 = lean_box(0);
x_29 = lean_apply_9(x_14, x_28, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_29;
}
else
{
lean_object* x_30; 
x_30 = lean_apply_10(x_13, x_24, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_30;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceOfInt___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceOfInt", 11);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceOfInt___closed__3;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4;
x_2 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOfInt), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__6;
x_4 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__7;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3284_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; 
x_12 = l_Lean_mkNatLit(x_1);
x_13 = l_Lean_mkNatLit(x_2);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_15 = l_Lean_mkAppB(x_14, x_12, x_13);
x_16 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_16, 0, x_15);
x_17 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_17, 0, x_16);
lean_ctor_set(x_17, 1, x_11);
return x_17;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_11 = l_Lean_Meta_getNatValue_x3f(x_1, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_11) == 0)
{
lean_object* x_12; 
x_12 = lean_ctor_get(x_11, 0);
lean_inc(x_12);
if (lean_obj_tag(x_12) == 0)
{
uint8_t x_13; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = !lean_is_exclusive(x_11);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
x_14 = lean_ctor_get(x_11, 0);
lean_dec(x_14);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_11, 0, x_15);
return x_11;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = lean_ctor_get(x_11, 1);
lean_inc(x_16);
lean_dec(x_11);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_18 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_18, 0, x_17);
lean_ctor_set(x_18, 1, x_16);
return x_18;
}
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_11, 1);
lean_inc(x_19);
lean_dec(x_11);
x_20 = lean_ctor_get(x_12, 0);
lean_inc(x_20);
lean_dec(x_12);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_21 = l_Lean_Meta_getNatValue_x3f(x_2, x_6, x_7, x_8, x_9, x_19);
if (lean_obj_tag(x_21) == 0)
{
lean_object* x_22; 
x_22 = lean_ctor_get(x_21, 0);
lean_inc(x_22);
if (lean_obj_tag(x_22) == 0)
{
uint8_t x_23; 
lean_dec(x_20);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_23 = !lean_is_exclusive(x_21);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; 
x_24 = lean_ctor_get(x_21, 0);
lean_dec(x_24);
x_25 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_25);
return x_21;
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_26 = lean_ctor_get(x_21, 1);
lean_inc(x_26);
lean_dec(x_21);
x_27 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_28 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_26);
return x_28;
}
}
else
{
uint8_t x_29; 
x_29 = !lean_is_exclusive(x_21);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; uint8_t x_34; 
x_30 = lean_ctor_get(x_21, 1);
x_31 = lean_ctor_get(x_21, 0);
lean_dec(x_31);
x_32 = lean_ctor_get(x_22, 0);
lean_inc(x_32);
lean_dec(x_22);
x_33 = l_BitVec_ofNat(x_20, x_32);
x_34 = lean_nat_dec_eq(x_33, x_32);
lean_dec(x_32);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; 
lean_free_object(x_21);
x_35 = lean_box(0);
x_36 = l_BitVec_reduceOfNat___lambda__1(x_20, x_33, x_35, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_30);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_36;
}
else
{
lean_object* x_37; 
lean_dec(x_33);
lean_dec(x_20);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_37 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_37);
return x_21;
}
}
else
{
lean_object* x_38; lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_38 = lean_ctor_get(x_21, 1);
lean_inc(x_38);
lean_dec(x_21);
x_39 = lean_ctor_get(x_22, 0);
lean_inc(x_39);
lean_dec(x_22);
x_40 = l_BitVec_ofNat(x_20, x_39);
x_41 = lean_nat_dec_eq(x_40, x_39);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; lean_object* x_43; 
x_42 = lean_box(0);
x_43 = l_BitVec_reduceOfNat___lambda__1(x_20, x_40, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_38);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_43;
}
else
{
lean_object* x_44; lean_object* x_45; 
lean_dec(x_40);
lean_dec(x_20);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_45 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_45, 0, x_44);
lean_ctor_set(x_45, 1, x_38);
return x_45;
}
}
}
}
else
{
uint8_t x_46; 
lean_dec(x_20);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_46 = !lean_is_exclusive(x_21);
if (x_46 == 0)
{
return x_21;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_47 = lean_ctor_get(x_21, 0);
x_48 = lean_ctor_get(x_21, 1);
lean_inc(x_48);
lean_inc(x_47);
lean_dec(x_21);
x_49 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_49, 0, x_47);
lean_ctor_set(x_49, 1, x_48);
return x_49;
}
}
}
}
else
{
uint8_t x_50; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_50 = !lean_is_exclusive(x_11);
if (x_50 == 0)
{
return x_11;
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_51 = lean_ctor_get(x_11, 0);
x_52 = lean_ctor_get(x_11, 1);
lean_inc(x_52);
lean_inc(x_51);
lean_dec(x_11);
x_53 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
return x_53;
}
}
}
}
static lean_object* _init_l_BitVec_reduceOfNat___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOfNat___lambda__2), 10, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceOfNat___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; lean_object* x_26; uint8_t x_27; 
x_24 = l_Lean_Expr_appArg(x_20, lean_box(0));
x_25 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_26 = l_BitVec_reduceUnary___lambda__1___closed__4;
x_27 = l_Lean_Expr_isConstOf(x_25, x_26);
lean_dec(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
lean_dec(x_24);
lean_dec(x_19);
x_28 = lean_box(0);
x_29 = lean_apply_9(x_14, x_28, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_29;
}
else
{
lean_object* x_30; 
x_30 = lean_apply_10(x_13, x_24, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_30;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceOfNat___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceOfNat", 11);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__4;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4;
x_2 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOfNat), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__6;
x_4 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__7;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3574_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
lean_dec(x_36);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_35);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_39 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_39);
return x_24;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; 
lean_free_object(x_24);
x_40 = lean_ctor_get(x_22, 1);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_nat_dec_lt(x_40, x_41);
lean_dec(x_41);
lean_dec(x_40);
x_43 = l_Lean_Meta_Simp_evalPropStep(x_1, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
return x_43;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_49 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_lt(x_51, x_52);
lean_dec(x_52);
lean_dec(x_51);
x_54 = l_Lean_Meta_Simp_evalPropStep(x_1, x_53, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_44);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_24);
if (x_55 == 0)
{
return x_24;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_24, 0);
x_57 = lean_ctor_get(x_24, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_24);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
static lean_object* _init_l_BitVec_reduceLT___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("LT", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLT___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("lt", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLT___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLT___closed__1;
x_2 = l_BitVec_reduceLT___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceLT___closed__3;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceLT___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceLT___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceLT", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLT___closed__3;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__4;
x_2 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__5;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__11() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceLT), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__10;
x_4 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__11;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__11;
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3617_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
lean_dec(x_36);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_35);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_39 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_39);
return x_24;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; 
lean_free_object(x_24);
x_40 = lean_ctor_get(x_22, 1);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_nat_dec_le(x_40, x_41);
lean_dec(x_41);
lean_dec(x_40);
x_43 = l_Lean_Meta_Simp_evalPropStep(x_1, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
return x_43;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_49 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_le(x_51, x_52);
lean_dec(x_52);
lean_dec(x_51);
x_54 = l_Lean_Meta_Simp_evalPropStep(x_1, x_53, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_44);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_24);
if (x_55 == 0)
{
return x_24;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_24, 0);
x_57 = lean_ctor_get(x_24, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_24);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
static lean_object* _init_l_BitVec_reduceLE___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("LE", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLE___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("le", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLE___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLE___closed__1;
x_2 = l_BitVec_reduceLE___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceLE___closed__3;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceLE___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceLE___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceLE", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLE___closed__3;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__4;
x_2 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__10() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceLE), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__9;
x_4 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__10;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__10;
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3660_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
lean_dec(x_36);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_35);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_39 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_39);
return x_24;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; 
lean_free_object(x_24);
x_40 = lean_ctor_get(x_22, 1);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_nat_dec_lt(x_41, x_40);
lean_dec(x_40);
lean_dec(x_41);
x_43 = l_Lean_Meta_Simp_evalPropStep(x_1, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
return x_43;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_49 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_lt(x_52, x_51);
lean_dec(x_51);
lean_dec(x_52);
x_54 = l_Lean_Meta_Simp_evalPropStep(x_1, x_53, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_44);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_24);
if (x_55 == 0)
{
return x_24;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_24, 0);
x_57 = lean_ctor_get(x_24, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_24);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
static lean_object* _init_l_BitVec_reduceGT___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("GT", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGT___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("gt", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGT___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGT___closed__1;
x_2 = l_BitVec_reduceGT___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceGT___closed__3;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceGT___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceGT___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceGT", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__3() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGT), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__10;
x_4 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__3;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__3;
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3703_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
lean_dec(x_36);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_35);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_39 = l_BitVec_reduceBinPred___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_39);
return x_24;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; 
lean_free_object(x_24);
x_40 = lean_ctor_get(x_22, 1);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_nat_dec_le(x_41, x_40);
lean_dec(x_40);
lean_dec(x_41);
x_43 = l_Lean_Meta_Simp_evalPropStep(x_1, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
return x_43;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_49 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_le(x_52, x_51);
lean_dec(x_51);
lean_dec(x_52);
x_54 = l_Lean_Meta_Simp_evalPropStep(x_1, x_53, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_44);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_24);
if (x_55 == 0)
{
return x_24;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_24, 0);
x_57 = lean_ctor_get(x_24, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_24);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
static lean_object* _init_l_BitVec_reduceGE___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("GE", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGE___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ge", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGE___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGE___closed__1;
x_2 = l_BitVec_reduceGE___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceGE___closed__3;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceBinPred___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceGE___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceGE___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceGE", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__3() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGE), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__9;
x_4 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__3;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__3;
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
lean_dec(x_35);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_dec_lt(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
x_42 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__9;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_lt(x_51, x_52);
lean_dec(x_52);
lean_dec(x_51);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
x_54 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_44);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_44);
return x_57;
}
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceULT___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ult", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceULT___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceULT___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceULT___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceULT___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceULT___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceULT", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceULT___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceULT), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__2;
x_3 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__7;
x_4 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3768_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
lean_dec(x_35);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_dec_le(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
x_42 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__9;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_le(x_51, x_52);
lean_dec(x_52);
lean_dec(x_51);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
x_54 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_44);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_44);
return x_57;
}
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceULE___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ule", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceULE___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceULE___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceULE___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceULE___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceULE___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceULE", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceULE___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceULE), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__2;
x_3 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__7;
x_4 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_slt(x_35, x_39, x_40);
lean_dec(x_35);
if (x_41 == 0)
{
lean_object* x_42; 
x_42 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__9;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_46);
lean_dec(x_45);
lean_dec(x_22);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = l_BitVec_slt(x_46, x_51, x_52);
lean_dec(x_46);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
x_54 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_44);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_44);
return x_57;
}
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSLT___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("slt", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSLT___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSLT___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSLT___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSLT___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSLT___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSLT", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSLT___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSLT), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3812_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_sle(x_35, x_39, x_40);
lean_dec(x_35);
if (x_41 == 0)
{
lean_object* x_42; 
x_42 = l_BitVec_reduceGetBit___lambda__1___closed__5;
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__9;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_46);
lean_dec(x_45);
lean_dec(x_22);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = l_BitVec_sle(x_46, x_51, x_52);
lean_dec(x_46);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
x_54 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_44);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_44);
return x_57;
}
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSLE___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("sle", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSLE___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSLE___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSLE___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSLE___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSLE___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSLE", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSLE___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSLE), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3834_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_11 = l_BitVec_fromExpr_x3f(x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_11) == 0)
{
lean_object* x_12; 
x_12 = lean_ctor_get(x_11, 0);
lean_inc(x_12);
if (lean_obj_tag(x_12) == 0)
{
uint8_t x_13; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_13 = !lean_is_exclusive(x_11);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
x_14 = lean_ctor_get(x_11, 0);
lean_dec(x_14);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_11, 0, x_15);
return x_11;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = lean_ctor_get(x_11, 1);
lean_inc(x_16);
lean_dec(x_11);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_18 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_18, 0, x_17);
lean_ctor_set(x_18, 1, x_16);
return x_18;
}
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_11, 1);
lean_inc(x_19);
lean_dec(x_11);
x_20 = lean_ctor_get(x_12, 0);
lean_inc(x_20);
lean_dec(x_12);
x_21 = l_Lean_Meta_getNatValue_x3f(x_1, x_6, x_7, x_8, x_9, x_19);
if (lean_obj_tag(x_21) == 0)
{
lean_object* x_22; 
x_22 = lean_ctor_get(x_21, 0);
lean_inc(x_22);
if (lean_obj_tag(x_22) == 0)
{
uint8_t x_23; 
lean_dec(x_20);
x_23 = !lean_is_exclusive(x_21);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; 
x_24 = lean_ctor_get(x_21, 0);
lean_dec(x_24);
x_25 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_25);
return x_21;
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_26 = lean_ctor_get(x_21, 1);
lean_inc(x_26);
lean_dec(x_21);
x_27 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_28 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_26);
return x_28;
}
}
else
{
uint8_t x_29; 
x_29 = !lean_is_exclusive(x_21);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; uint8_t x_33; 
x_30 = lean_ctor_get(x_21, 0);
lean_dec(x_30);
x_31 = lean_ctor_get(x_22, 0);
lean_inc(x_31);
lean_dec(x_22);
x_32 = lean_ctor_get(x_20, 0);
lean_inc(x_32);
x_33 = lean_nat_dec_le(x_32, x_31);
lean_dec(x_32);
if (x_33 == 0)
{
lean_object* x_34; 
lean_dec(x_31);
lean_dec(x_20);
x_34 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_34);
return x_21;
}
else
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_35 = lean_ctor_get(x_20, 1);
lean_inc(x_35);
lean_dec(x_20);
x_36 = l_Lean_mkNatLit(x_31);
x_37 = l_Lean_mkNatLit(x_35);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_39 = l_Lean_mkAppB(x_38, x_36, x_37);
x_40 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_40, 0, x_39);
lean_ctor_set(x_21, 0, x_40);
return x_21;
}
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
x_41 = lean_ctor_get(x_21, 1);
lean_inc(x_41);
lean_dec(x_21);
x_42 = lean_ctor_get(x_22, 0);
lean_inc(x_42);
lean_dec(x_22);
x_43 = lean_ctor_get(x_20, 0);
lean_inc(x_43);
x_44 = lean_nat_dec_le(x_43, x_42);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; 
lean_dec(x_42);
lean_dec(x_20);
x_45 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_46 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_46, 1, x_41);
return x_46;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_47 = lean_ctor_get(x_20, 1);
lean_inc(x_47);
lean_dec(x_20);
x_48 = l_Lean_mkNatLit(x_42);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_41);
return x_53;
}
}
}
}
else
{
uint8_t x_54; 
lean_dec(x_20);
x_54 = !lean_is_exclusive(x_21);
if (x_54 == 0)
{
return x_21;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_21, 0);
x_56 = lean_ctor_get(x_21, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_21);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_11);
if (x_58 == 0)
{
return x_11;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_11, 0);
x_60 = lean_ctor_get(x_11, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_11);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend_x27___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceZeroExtend_x27___lambda__1___boxed), 10, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend_x27___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("zeroExtend'", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend_x27___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceZeroExtend_x27___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceZeroExtend_x27___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; uint8_t x_25; 
x_24 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_25 = l_Lean_Expr_isApp(x_24);
if (x_25 == 0)
{
lean_object* x_26; lean_object* x_27; 
lean_dec(x_24);
lean_dec(x_19);
x_26 = lean_box(0);
x_27 = lean_apply_9(x_14, x_26, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_27;
}
else
{
lean_object* x_28; lean_object* x_29; uint8_t x_30; 
x_28 = l_Lean_Expr_appArg(x_24, lean_box(0));
x_29 = l_Lean_Expr_appFnCleanup(x_24, lean_box(0));
x_30 = l_Lean_Expr_isApp(x_29);
if (x_30 == 0)
{
lean_object* x_31; lean_object* x_32; 
lean_dec(x_29);
lean_dec(x_28);
lean_dec(x_19);
x_31 = lean_box(0);
x_32 = lean_apply_9(x_14, x_31, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_32;
}
else
{
lean_object* x_33; lean_object* x_34; uint8_t x_35; 
x_33 = l_Lean_Expr_appFnCleanup(x_29, lean_box(0));
x_34 = l_BitVec_reduceZeroExtend_x27___closed__3;
x_35 = l_Lean_Expr_isConstOf(x_33, x_34);
lean_dec(x_33);
if (x_35 == 0)
{
lean_object* x_36; lean_object* x_37; 
lean_dec(x_28);
lean_dec(x_19);
x_36 = lean_box(0);
x_37 = lean_apply_9(x_14, x_36, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_37;
}
else
{
lean_object* x_38; 
x_38 = lean_apply_10(x_13, x_28, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_38;
}
}
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceZeroExtend_x27___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceZeroExtend'", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceZeroExtend_x27___closed__3;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6;
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceZeroExtend_x27), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__2;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__8;
x_4 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__9;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4159_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_11 = l_BitVec_fromExpr_x3f(x_1, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_11) == 0)
{
lean_object* x_12; 
x_12 = lean_ctor_get(x_11, 0);
lean_inc(x_12);
if (lean_obj_tag(x_12) == 0)
{
uint8_t x_13; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_2);
x_13 = !lean_is_exclusive(x_11);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
x_14 = lean_ctor_get(x_11, 0);
lean_dec(x_14);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_11, 0, x_15);
return x_11;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = lean_ctor_get(x_11, 1);
lean_inc(x_16);
lean_dec(x_11);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_18 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_18, 0, x_17);
lean_ctor_set(x_18, 1, x_16);
return x_18;
}
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_11, 1);
lean_inc(x_19);
lean_dec(x_11);
x_20 = lean_ctor_get(x_12, 0);
lean_inc(x_20);
lean_dec(x_12);
x_21 = l_Lean_Meta_getNatValue_x3f(x_2, x_6, x_7, x_8, x_9, x_19);
if (lean_obj_tag(x_21) == 0)
{
lean_object* x_22; 
x_22 = lean_ctor_get(x_21, 0);
lean_inc(x_22);
if (lean_obj_tag(x_22) == 0)
{
uint8_t x_23; 
lean_dec(x_20);
x_23 = !lean_is_exclusive(x_21);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; 
x_24 = lean_ctor_get(x_21, 0);
lean_dec(x_24);
x_25 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_25);
return x_21;
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_26 = lean_ctor_get(x_21, 1);
lean_inc(x_26);
lean_dec(x_21);
x_27 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_28 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_26);
return x_28;
}
}
else
{
uint8_t x_29; 
x_29 = !lean_is_exclusive(x_21);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_30 = lean_ctor_get(x_21, 0);
lean_dec(x_30);
x_31 = lean_ctor_get(x_22, 0);
lean_inc(x_31);
lean_dec(x_22);
x_32 = lean_ctor_get(x_20, 0);
lean_inc(x_32);
x_33 = lean_nat_add(x_32, x_31);
lean_dec(x_32);
x_34 = lean_ctor_get(x_20, 1);
lean_inc(x_34);
lean_dec(x_20);
x_35 = lean_nat_shiftl(x_34, x_31);
lean_dec(x_31);
lean_dec(x_34);
x_36 = l_Lean_mkNatLit(x_33);
x_37 = l_Lean_mkNatLit(x_35);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_39 = l_Lean_mkAppB(x_38, x_36, x_37);
x_40 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_40, 0, x_39);
lean_ctor_set(x_21, 0, x_40);
return x_21;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_41 = lean_ctor_get(x_21, 1);
lean_inc(x_41);
lean_dec(x_21);
x_42 = lean_ctor_get(x_22, 0);
lean_inc(x_42);
lean_dec(x_22);
x_43 = lean_ctor_get(x_20, 0);
lean_inc(x_43);
x_44 = lean_nat_add(x_43, x_42);
lean_dec(x_43);
x_45 = lean_ctor_get(x_20, 1);
lean_inc(x_45);
lean_dec(x_20);
x_46 = lean_nat_shiftl(x_45, x_42);
lean_dec(x_42);
lean_dec(x_45);
x_47 = l_Lean_mkNatLit(x_44);
x_48 = l_Lean_mkNatLit(x_46);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_50 = l_Lean_mkAppB(x_49, x_47, x_48);
x_51 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_51, 0, x_50);
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_41);
return x_52;
}
}
}
else
{
uint8_t x_53; 
lean_dec(x_20);
x_53 = !lean_is_exclusive(x_21);
if (x_53 == 0)
{
return x_21;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_54 = lean_ctor_get(x_21, 0);
x_55 = lean_ctor_get(x_21, 1);
lean_inc(x_55);
lean_inc(x_54);
lean_dec(x_21);
x_56 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_56, 0, x_54);
lean_ctor_set(x_56, 1, x_55);
return x_56;
}
}
}
}
else
{
uint8_t x_57; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_2);
x_57 = !lean_is_exclusive(x_11);
if (x_57 == 0)
{
return x_11;
}
else
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_58 = lean_ctor_get(x_11, 0);
x_59 = lean_ctor_get(x_11, 1);
lean_inc(x_59);
lean_inc(x_58);
lean_dec(x_11);
x_60 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
return x_60;
}
}
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftZeroExtend___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeftZeroExtend___lambda__1___boxed), 10, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftZeroExtend___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("shiftLeftZeroExtend", 19);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftZeroExtend___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceShiftLeftZeroExtend___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceShiftLeftZeroExtend___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appArg(x_20, lean_box(0));
x_25 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_26 = l_Lean_Expr_isApp(x_25);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
lean_dec(x_25);
lean_dec(x_24);
lean_dec(x_19);
x_27 = lean_box(0);
x_28 = lean_apply_9(x_14, x_27, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_28;
}
else
{
lean_object* x_29; lean_object* x_30; uint8_t x_31; 
x_29 = l_Lean_Expr_appFnCleanup(x_25, lean_box(0));
x_30 = l_BitVec_reduceShiftLeftZeroExtend___closed__3;
x_31 = l_Lean_Expr_isConstOf(x_29, x_30);
lean_dec(x_29);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; 
lean_dec(x_24);
lean_dec(x_19);
x_32 = lean_box(0);
x_33 = lean_apply_9(x_14, x_32, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_33;
}
else
{
lean_object* x_34; 
x_34 = lean_apply_10(x_13, x_24, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_34;
}
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceShiftLeftZeroExtend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceShiftLeftZeroExtend", 25);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceShiftLeftZeroExtend___closed__3;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeftZeroExtend), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__2;
x_3 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__7;
x_4 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4426_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_12 = l_BitVec_fromExpr_x3f(x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_22 = l_Lean_Meta_getNatValue_x3f(x_1, x_7, x_8, x_9, x_10, x_20);
if (lean_obj_tag(x_22) == 0)
{
lean_object* x_23; 
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
if (lean_obj_tag(x_23) == 0)
{
uint8_t x_24; 
lean_dec(x_21);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_24 = !lean_is_exclusive(x_22);
if (x_24 == 0)
{
lean_object* x_25; lean_object* x_26; 
x_25 = lean_ctor_get(x_22, 0);
lean_dec(x_25);
x_26 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_22, 0, x_26);
return x_22;
}
else
{
lean_object* x_27; lean_object* x_28; lean_object* x_29; 
x_27 = lean_ctor_get(x_22, 1);
lean_inc(x_27);
lean_dec(x_22);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_29 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_29, 0, x_28);
lean_ctor_set(x_29, 1, x_27);
return x_29;
}
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_22, 1);
lean_inc(x_30);
lean_dec(x_22);
x_31 = lean_ctor_get(x_23, 0);
lean_inc(x_31);
lean_dec(x_23);
x_32 = l_Lean_Meta_getNatValue_x3f(x_2, x_7, x_8, x_9, x_10, x_30);
if (lean_obj_tag(x_32) == 0)
{
lean_object* x_33; 
x_33 = lean_ctor_get(x_32, 0);
lean_inc(x_33);
if (lean_obj_tag(x_33) == 0)
{
uint8_t x_34; 
lean_dec(x_31);
lean_dec(x_21);
x_34 = !lean_is_exclusive(x_32);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; 
x_35 = lean_ctor_get(x_32, 0);
lean_dec(x_35);
x_36 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_32, 0, x_36);
return x_32;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; 
x_37 = lean_ctor_get(x_32, 1);
lean_inc(x_37);
lean_dec(x_32);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_39 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_39, 0, x_38);
lean_ctor_set(x_39, 1, x_37);
return x_39;
}
}
else
{
uint8_t x_40; 
x_40 = !lean_is_exclusive(x_32);
if (x_40 == 0)
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_41 = lean_ctor_get(x_32, 0);
lean_dec(x_41);
x_42 = lean_ctor_get(x_33, 0);
lean_inc(x_42);
lean_dec(x_33);
x_43 = lean_ctor_get(x_21, 1);
lean_inc(x_43);
lean_dec(x_21);
x_44 = l_BitVec_extractLsb_x27___rarg(x_31, x_42, x_43);
lean_dec(x_43);
lean_dec(x_31);
x_45 = l_Lean_mkNatLit(x_42);
x_46 = l_Lean_mkNatLit(x_44);
x_47 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_48 = l_Lean_mkAppB(x_47, x_45, x_46);
x_49 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_49, 0, x_48);
lean_ctor_set(x_32, 0, x_49);
return x_32;
}
else
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_50 = lean_ctor_get(x_32, 1);
lean_inc(x_50);
lean_dec(x_32);
x_51 = lean_ctor_get(x_33, 0);
lean_inc(x_51);
lean_dec(x_33);
x_52 = lean_ctor_get(x_21, 1);
lean_inc(x_52);
lean_dec(x_21);
x_53 = l_BitVec_extractLsb_x27___rarg(x_31, x_51, x_52);
lean_dec(x_52);
lean_dec(x_31);
x_54 = l_Lean_mkNatLit(x_51);
x_55 = l_Lean_mkNatLit(x_53);
x_56 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_57 = l_Lean_mkAppB(x_56, x_54, x_55);
x_58 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_58, 0, x_57);
x_59 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_59, 0, x_58);
lean_ctor_set(x_59, 1, x_50);
return x_59;
}
}
}
else
{
uint8_t x_60; 
lean_dec(x_31);
lean_dec(x_21);
x_60 = !lean_is_exclusive(x_32);
if (x_60 == 0)
{
return x_32;
}
else
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_61 = lean_ctor_get(x_32, 0);
x_62 = lean_ctor_get(x_32, 1);
lean_inc(x_62);
lean_inc(x_61);
lean_dec(x_32);
x_63 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_63, 0, x_61);
lean_ctor_set(x_63, 1, x_62);
return x_63;
}
}
}
}
else
{
uint8_t x_64; 
lean_dec(x_21);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
x_64 = !lean_is_exclusive(x_22);
if (x_64 == 0)
{
return x_22;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_65 = lean_ctor_get(x_22, 0);
x_66 = lean_ctor_get(x_22, 1);
lean_inc(x_66);
lean_inc(x_65);
lean_dec(x_22);
x_67 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_67, 0, x_65);
lean_ctor_set(x_67, 1, x_66);
return x_67;
}
}
}
}
else
{
uint8_t x_68; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_68 = !lean_is_exclusive(x_12);
if (x_68 == 0)
{
return x_12;
}
else
{
lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_69 = lean_ctor_get(x_12, 0);
x_70 = lean_ctor_get(x_12, 1);
lean_inc(x_70);
lean_inc(x_69);
lean_dec(x_12);
x_71 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
return x_71;
}
}
}
}
static lean_object* _init_l_BitVec_reduceExtracLsb_x27___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceExtracLsb_x27___lambda__1___boxed), 11, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceExtracLsb_x27___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("extractLsb'", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceExtracLsb_x27___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceExtracLsb_x27___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceExtracLsb_x27___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appArg(x_20, lean_box(0));
x_25 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_26 = l_Lean_Expr_isApp(x_25);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
lean_dec(x_25);
lean_dec(x_24);
lean_dec(x_19);
x_27 = lean_box(0);
x_28 = lean_apply_9(x_14, x_27, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_28;
}
else
{
lean_object* x_29; lean_object* x_30; uint8_t x_31; 
x_29 = l_Lean_Expr_appArg(x_25, lean_box(0));
x_30 = l_Lean_Expr_appFnCleanup(x_25, lean_box(0));
x_31 = l_Lean_Expr_isApp(x_30);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; 
lean_dec(x_30);
lean_dec(x_29);
lean_dec(x_24);
lean_dec(x_19);
x_32 = lean_box(0);
x_33 = lean_apply_9(x_14, x_32, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_33;
}
else
{
lean_object* x_34; lean_object* x_35; uint8_t x_36; 
x_34 = l_Lean_Expr_appFnCleanup(x_30, lean_box(0));
x_35 = l_BitVec_reduceExtracLsb_x27___closed__3;
x_36 = l_Lean_Expr_isConstOf(x_34, x_35);
lean_dec(x_34);
if (x_36 == 0)
{
lean_object* x_37; lean_object* x_38; 
lean_dec(x_29);
lean_dec(x_24);
lean_dec(x_19);
x_37 = lean_box(0);
x_38 = lean_apply_9(x_14, x_37, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_38;
}
else
{
lean_object* x_39; 
x_39 = lean_apply_11(x_13, x_29, x_24, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_39;
}
}
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceExtracLsb_x27___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
return x_12;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceExtracLsb'", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceExtracLsb_x27___closed__3;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6;
x_2 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceExtracLsb_x27), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__2;
x_3 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__8;
x_4 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__9;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4773_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_11 = l_BitVec_fromExpr_x3f(x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_11) == 0)
{
lean_object* x_12; 
x_12 = lean_ctor_get(x_11, 0);
lean_inc(x_12);
if (lean_obj_tag(x_12) == 0)
{
uint8_t x_13; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_13 = !lean_is_exclusive(x_11);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
x_14 = lean_ctor_get(x_11, 0);
lean_dec(x_14);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_11, 0, x_15);
return x_11;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = lean_ctor_get(x_11, 1);
lean_inc(x_16);
lean_dec(x_11);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_18 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_18, 0, x_17);
lean_ctor_set(x_18, 1, x_16);
return x_18;
}
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_11, 1);
lean_inc(x_19);
lean_dec(x_11);
x_20 = lean_ctor_get(x_12, 0);
lean_inc(x_20);
lean_dec(x_12);
x_21 = l_Lean_Meta_getNatValue_x3f(x_1, x_6, x_7, x_8, x_9, x_19);
if (lean_obj_tag(x_21) == 0)
{
lean_object* x_22; 
x_22 = lean_ctor_get(x_21, 0);
lean_inc(x_22);
if (lean_obj_tag(x_22) == 0)
{
uint8_t x_23; 
lean_dec(x_20);
x_23 = !lean_is_exclusive(x_21);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; 
x_24 = lean_ctor_get(x_21, 0);
lean_dec(x_24);
x_25 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_25);
return x_21;
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_26 = lean_ctor_get(x_21, 1);
lean_inc(x_26);
lean_dec(x_21);
x_27 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_28 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_26);
return x_28;
}
}
else
{
uint8_t x_29; 
x_29 = !lean_is_exclusive(x_21);
if (x_29 == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; 
x_30 = lean_ctor_get(x_21, 0);
lean_dec(x_30);
x_31 = lean_ctor_get(x_22, 0);
lean_inc(x_31);
lean_dec(x_22);
x_32 = lean_ctor_get(x_20, 0);
lean_inc(x_32);
x_33 = lean_nat_mul(x_32, x_31);
x_34 = lean_ctor_get(x_20, 1);
lean_inc(x_34);
lean_dec(x_20);
x_35 = l_BitVec_replicate(x_32, x_31, x_34);
lean_dec(x_34);
lean_dec(x_31);
lean_dec(x_32);
x_36 = l_Lean_mkNatLit(x_33);
x_37 = l_Lean_mkNatLit(x_35);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_39 = l_Lean_mkAppB(x_38, x_36, x_37);
x_40 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_40, 0, x_39);
lean_ctor_set(x_21, 0, x_40);
return x_21;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_41 = lean_ctor_get(x_21, 1);
lean_inc(x_41);
lean_dec(x_21);
x_42 = lean_ctor_get(x_22, 0);
lean_inc(x_42);
lean_dec(x_22);
x_43 = lean_ctor_get(x_20, 0);
lean_inc(x_43);
x_44 = lean_nat_mul(x_43, x_42);
x_45 = lean_ctor_get(x_20, 1);
lean_inc(x_45);
lean_dec(x_20);
x_46 = l_BitVec_replicate(x_43, x_42, x_45);
lean_dec(x_45);
lean_dec(x_42);
lean_dec(x_43);
x_47 = l_Lean_mkNatLit(x_44);
x_48 = l_Lean_mkNatLit(x_46);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_50 = l_Lean_mkAppB(x_49, x_47, x_48);
x_51 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_51, 0, x_50);
x_52 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_41);
return x_52;
}
}
}
else
{
uint8_t x_53; 
lean_dec(x_20);
x_53 = !lean_is_exclusive(x_21);
if (x_53 == 0)
{
return x_21;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_54 = lean_ctor_get(x_21, 0);
x_55 = lean_ctor_get(x_21, 1);
lean_inc(x_55);
lean_inc(x_54);
lean_dec(x_21);
x_56 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_56, 0, x_54);
lean_ctor_set(x_56, 1, x_55);
return x_56;
}
}
}
}
else
{
uint8_t x_57; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_57 = !lean_is_exclusive(x_11);
if (x_57 == 0)
{
return x_11;
}
else
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_58 = lean_ctor_get(x_11, 0);
x_59 = lean_ctor_get(x_11, 1);
lean_inc(x_59);
lean_inc(x_58);
lean_dec(x_11);
x_60 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
return x_60;
}
}
}
}
static lean_object* _init_l_BitVec_reduceReplicate___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceReplicate___lambda__1___boxed), 10, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceReplicate___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("replicate", 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceReplicate___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceReplicate___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceReplicate___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appArg(x_20, lean_box(0));
x_25 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_26 = l_Lean_Expr_isApp(x_25);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
lean_dec(x_25);
lean_dec(x_24);
lean_dec(x_19);
x_27 = lean_box(0);
x_28 = lean_apply_9(x_14, x_27, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_28;
}
else
{
lean_object* x_29; lean_object* x_30; uint8_t x_31; 
x_29 = l_Lean_Expr_appFnCleanup(x_25, lean_box(0));
x_30 = l_BitVec_reduceReplicate___closed__3;
x_31 = l_Lean_Expr_isConstOf(x_29, x_30);
lean_dec(x_29);
if (x_31 == 0)
{
lean_object* x_32; lean_object* x_33; 
lean_dec(x_24);
lean_dec(x_19);
x_32 = lean_box(0);
x_33 = lean_apply_9(x_14, x_32, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_33;
}
else
{
lean_object* x_34; 
x_34 = lean_apply_10(x_13, x_24, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_34;
}
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceReplicate___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceReplicate", 15);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceReplicate___closed__3;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceReplicate), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__2;
x_3 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__7;
x_4 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5040_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
x_22 = l_Lean_Expr_appFn_x21(x_1);
x_23 = l_Lean_Expr_appArg_x21(x_22);
lean_dec(x_22);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_20);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_21);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_21, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_21, 1);
lean_inc(x_36);
lean_dec(x_21);
x_37 = l_BitVec_zeroExtend(x_35, x_34, x_36);
lean_dec(x_36);
lean_dec(x_35);
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_43 = lean_ctor_get(x_24, 1);
lean_inc(x_43);
lean_dec(x_24);
x_44 = lean_ctor_get(x_25, 0);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_21, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_21, 1);
lean_inc(x_46);
lean_dec(x_21);
x_47 = l_BitVec_zeroExtend(x_45, x_44, x_46);
lean_dec(x_46);
lean_dec(x_45);
x_48 = l_Lean_mkNatLit(x_44);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
lean_dec(x_21);
x_54 = !lean_is_exclusive(x_24);
if (x_54 == 0)
{
return x_24;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_24, 0);
x_56 = lean_ctor_get(x_24, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_24);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_12);
if (x_58 == 0)
{
return x_12;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_12, 0);
x_60 = lean_ctor_get(x_12, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_12);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("zeroExtend", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceZeroExtend___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceZeroExtend___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceZeroExtend___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceZeroExtend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceZeroExtend", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceZeroExtend___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceZeroExtend), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__2;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__7;
x_4 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5061_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
x_22 = l_Lean_Expr_appFn_x21(x_1);
x_23 = l_Lean_Expr_appArg_x21(x_22);
lean_dec(x_22);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_20);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_21);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_21, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_21, 1);
lean_inc(x_36);
lean_dec(x_21);
x_37 = l_BitVec_signExtend(x_35, x_34, x_36);
lean_dec(x_35);
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_42, 0, x_41);
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_43 = lean_ctor_get(x_24, 1);
lean_inc(x_43);
lean_dec(x_24);
x_44 = lean_ctor_get(x_25, 0);
lean_inc(x_44);
lean_dec(x_25);
x_45 = lean_ctor_get(x_21, 0);
lean_inc(x_45);
x_46 = lean_ctor_get(x_21, 1);
lean_inc(x_46);
lean_dec(x_21);
x_47 = l_BitVec_signExtend(x_45, x_44, x_46);
lean_dec(x_45);
x_48 = l_Lean_mkNatLit(x_44);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_52, 0, x_51);
x_53 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_53, 0, x_52);
lean_ctor_set(x_53, 1, x_43);
return x_53;
}
}
}
else
{
uint8_t x_54; 
lean_dec(x_21);
x_54 = !lean_is_exclusive(x_24);
if (x_54 == 0)
{
return x_24;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_55 = lean_ctor_get(x_24, 0);
x_56 = lean_ctor_get(x_24, 1);
lean_inc(x_56);
lean_inc(x_55);
lean_dec(x_24);
x_57 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_57, 0, x_55);
lean_ctor_set(x_57, 1, x_56);
return x_57;
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_58 = !lean_is_exclusive(x_12);
if (x_58 == 0)
{
return x_12;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_12, 0);
x_60 = lean_ctor_get(x_12, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_12);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSignExtend___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("signExtend", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSignExtend___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSignExtend___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSignExtend___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSignExtend___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSignExtend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSignExtend", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSignExtend___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSignExtend), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__8;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5082_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_Lean_Meta_getNatValue_x3f(x_1, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_10) == 0)
{
lean_object* x_11; 
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
if (lean_obj_tag(x_11) == 0)
{
uint8_t x_12; 
x_12 = !lean_is_exclusive(x_10);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
x_13 = lean_ctor_get(x_10, 0);
lean_dec(x_13);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_10, 0, x_14);
return x_10;
}
else
{
lean_object* x_15; lean_object* x_16; lean_object* x_17; 
x_15 = lean_ctor_get(x_10, 1);
lean_inc(x_15);
lean_dec(x_10);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_17 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_17, 0, x_16);
lean_ctor_set(x_17, 1, x_15);
return x_17;
}
}
else
{
uint8_t x_18; 
x_18 = !lean_is_exclusive(x_10);
if (x_18 == 0)
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_19 = lean_ctor_get(x_10, 0);
lean_dec(x_19);
x_20 = lean_ctor_get(x_11, 0);
lean_inc(x_20);
lean_dec(x_11);
x_21 = l_BitVec_allOnes(x_20);
x_22 = l_Lean_mkNatLit(x_20);
x_23 = l_Lean_mkNatLit(x_21);
x_24 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_25 = l_Lean_mkAppB(x_24, x_22, x_23);
x_26 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_26, 0, x_25);
lean_ctor_set(x_10, 0, x_26);
return x_10;
}
else
{
lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; 
x_27 = lean_ctor_get(x_10, 1);
lean_inc(x_27);
lean_dec(x_10);
x_28 = lean_ctor_get(x_11, 0);
lean_inc(x_28);
lean_dec(x_11);
x_29 = l_BitVec_allOnes(x_28);
x_30 = l_Lean_mkNatLit(x_28);
x_31 = l_Lean_mkNatLit(x_29);
x_32 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_33 = l_Lean_mkAppB(x_32, x_30, x_31);
x_34 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_34, 0, x_33);
x_35 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_35, 0, x_34);
lean_ctor_set(x_35, 1, x_27);
return x_35;
}
}
}
else
{
uint8_t x_36; 
x_36 = !lean_is_exclusive(x_10);
if (x_36 == 0)
{
return x_10;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; 
x_37 = lean_ctor_get(x_10, 0);
x_38 = lean_ctor_get(x_10, 1);
lean_inc(x_38);
lean_inc(x_37);
lean_dec(x_10);
x_39 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_39, 0, x_37);
lean_ctor_set(x_39, 1, x_38);
return x_39;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAllOnes___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAllOnes___lambda__1___boxed), 9, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAllOnes___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("allOnes", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAllOnes___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceAllOnes___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceAllOnes___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; uint8_t x_22; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_BitVec_reduceAllOnes___closed__3;
x_22 = l_Lean_Expr_isConstOf(x_20, x_21);
lean_dec(x_20);
if (x_22 == 0)
{
lean_object* x_23; lean_object* x_24; 
lean_dec(x_19);
x_23 = lean_box(0);
x_24 = lean_apply_9(x_14, x_23, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_24;
}
else
{
lean_object* x_25; 
x_25 = lean_apply_9(x_13, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_25;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAllOnes___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAllOnes", 13);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAllOnes___closed__3;
x_2 = lean_unsigned_to_nat(1u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAllOnes), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__6;
x_4 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__7;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5241_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_11 = l_Lean_Meta_evalNat(x_1, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_11) == 0)
{
lean_object* x_12; 
x_12 = lean_ctor_get(x_11, 0);
lean_inc(x_12);
if (lean_obj_tag(x_12) == 0)
{
uint8_t x_13; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_2);
x_13 = !lean_is_exclusive(x_11);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
x_14 = lean_ctor_get(x_11, 0);
lean_dec(x_14);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_11, 0, x_15);
return x_11;
}
else
{
lean_object* x_16; lean_object* x_17; lean_object* x_18; 
x_16 = lean_ctor_get(x_11, 1);
lean_inc(x_16);
lean_dec(x_11);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_18 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_18, 0, x_17);
lean_ctor_set(x_18, 1, x_16);
return x_18;
}
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_11, 1);
lean_inc(x_19);
lean_dec(x_11);
x_20 = lean_ctor_get(x_12, 0);
lean_inc(x_20);
lean_dec(x_12);
x_21 = l_Lean_Meta_getFinValue_x3f(x_2, x_6, x_7, x_8, x_9, x_19);
if (lean_obj_tag(x_21) == 0)
{
lean_object* x_22; 
x_22 = lean_ctor_get(x_21, 0);
lean_inc(x_22);
if (lean_obj_tag(x_22) == 0)
{
uint8_t x_23; 
lean_dec(x_20);
x_23 = !lean_is_exclusive(x_21);
if (x_23 == 0)
{
lean_object* x_24; lean_object* x_25; 
x_24 = lean_ctor_get(x_21, 0);
lean_dec(x_24);
x_25 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_21, 0, x_25);
return x_21;
}
else
{
lean_object* x_26; lean_object* x_27; lean_object* x_28; 
x_26 = lean_ctor_get(x_21, 1);
lean_inc(x_26);
lean_dec(x_21);
x_27 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_28 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_28, 0, x_27);
lean_ctor_set(x_28, 1, x_26);
return x_28;
}
}
else
{
lean_object* x_29; uint8_t x_30; 
x_29 = lean_ctor_get(x_22, 0);
lean_inc(x_29);
lean_dec(x_22);
x_30 = !lean_is_exclusive(x_21);
if (x_30 == 0)
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_31 = lean_ctor_get(x_21, 0);
lean_dec(x_31);
x_32 = lean_ctor_get(x_29, 1);
lean_inc(x_32);
lean_dec(x_29);
x_33 = l_BitVec_ofNat(x_20, x_32);
lean_dec(x_32);
x_34 = l_Lean_mkNatLit(x_20);
x_35 = l_Lean_mkNatLit(x_33);
x_36 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_37 = l_Lean_mkAppB(x_36, x_34, x_35);
x_38 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_21, 0, x_38);
return x_21;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; 
x_39 = lean_ctor_get(x_21, 1);
lean_inc(x_39);
lean_dec(x_21);
x_40 = lean_ctor_get(x_29, 1);
lean_inc(x_40);
lean_dec(x_29);
x_41 = l_BitVec_ofNat(x_20, x_40);
lean_dec(x_40);
x_42 = l_Lean_mkNatLit(x_20);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_45 = l_Lean_mkAppB(x_44, x_42, x_43);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
x_47 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_47, 0, x_46);
lean_ctor_set(x_47, 1, x_39);
return x_47;
}
}
}
else
{
uint8_t x_48; 
lean_dec(x_20);
x_48 = !lean_is_exclusive(x_21);
if (x_48 == 0)
{
return x_21;
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; 
x_49 = lean_ctor_get(x_21, 0);
x_50 = lean_ctor_get(x_21, 1);
lean_inc(x_50);
lean_inc(x_49);
lean_dec(x_21);
x_51 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_51, 0, x_49);
lean_ctor_set(x_51, 1, x_50);
return x_51;
}
}
}
}
else
{
uint8_t x_52; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_2);
x_52 = !lean_is_exclusive(x_11);
if (x_52 == 0)
{
return x_11;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_53 = lean_ctor_get(x_11, 0);
x_54 = lean_ctor_get(x_11, 1);
lean_inc(x_54);
lean_inc(x_53);
lean_dec(x_11);
x_55 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_55, 0, x_53);
lean_ctor_set(x_55, 1, x_54);
return x_55;
}
}
}
}
static lean_object* _init_l_BitVec_reduceBitVecOfFin___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceBitVecOfFin___lambda__1___boxed), 10, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecOfFin___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ofFin", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecOfFin___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceBitVecOfFin___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceBitVecOfFin___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; lean_object* x_26; uint8_t x_27; 
x_24 = l_Lean_Expr_appArg(x_20, lean_box(0));
x_25 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_26 = l_BitVec_reduceBitVecOfFin___closed__3;
x_27 = l_Lean_Expr_isConstOf(x_25, x_26);
lean_dec(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
lean_dec(x_24);
lean_dec(x_19);
x_28 = lean_box(0);
x_29 = lean_apply_9(x_14, x_28, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_29;
}
else
{
lean_object* x_30; 
x_30 = lean_apply_10(x_13, x_24, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_30;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecOfFin___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceBitVecOfFin___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceBitVecOfFin", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBitVecOfFin___closed__3;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4;
x_2 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceBitVecOfFin), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__2;
x_3 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__6;
x_4 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__7;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5490_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("OfNat", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBitVecToFin___lambda__1___closed__1;
x_2 = l_BitVec_reduceUnary___lambda__1___closed__3;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBitVecToFin___lambda__1___closed__2;
x_2 = l_BitVec_reduceToInt___lambda__1___closed__3;
x_3 = l_Lean_Expr_const___override(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__4() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Fin", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceBitVecToFin___lambda__1___closed__4;
x_3 = l_Lean_Name_str___override(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceBitVecToFin___lambda__1___closed__5;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("instOfNat", 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBitVecToFin___lambda__1___closed__4;
x_2 = l_BitVec_reduceBitVecToFin___lambda__1___closed__7;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceBitVecToFin___lambda__1___closed__8;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_Lean_Meta_getBitVecValue_x3f(x_1, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_10) == 0)
{
lean_object* x_11; 
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
if (lean_obj_tag(x_11) == 0)
{
uint8_t x_12; 
x_12 = !lean_is_exclusive(x_10);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
x_13 = lean_ctor_get(x_10, 0);
lean_dec(x_13);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_10, 0, x_14);
return x_10;
}
else
{
lean_object* x_15; lean_object* x_16; lean_object* x_17; 
x_15 = lean_ctor_get(x_10, 1);
lean_inc(x_15);
lean_dec(x_10);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_17 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_17, 0, x_16);
lean_ctor_set(x_17, 1, x_15);
return x_17;
}
}
else
{
lean_object* x_18; uint8_t x_19; 
x_18 = lean_ctor_get(x_11, 0);
lean_inc(x_18);
lean_dec(x_11);
x_19 = !lean_is_exclusive(x_10);
if (x_19 == 0)
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_20 = lean_ctor_get(x_10, 0);
lean_dec(x_20);
x_21 = lean_ctor_get(x_18, 0);
lean_inc(x_21);
x_22 = lean_ctor_get(x_18, 1);
lean_inc(x_22);
lean_dec(x_18);
x_23 = lean_unsigned_to_nat(2u);
x_24 = lean_nat_pow(x_23, x_21);
lean_dec(x_21);
x_25 = l_Lean_mkRawNatLit(x_22);
lean_inc(x_24);
x_26 = l_Lean_mkNatLit(x_24);
x_27 = l_BitVec_reduceBitVecToFin___lambda__1___closed__6;
x_28 = l_Lean_Expr_app___override(x_27, x_26);
x_29 = lean_unsigned_to_nat(1u);
x_30 = lean_nat_sub(x_24, x_29);
lean_dec(x_24);
x_31 = l_Lean_mkNatLit(x_30);
x_32 = l_BitVec_reduceBitVecToFin___lambda__1___closed__9;
lean_inc(x_25);
x_33 = l_Lean_mkAppB(x_32, x_31, x_25);
x_34 = l_BitVec_reduceBitVecToFin___lambda__1___closed__3;
x_35 = l_Lean_mkApp3(x_34, x_28, x_25, x_33);
x_36 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_36, 0, x_35);
lean_ctor_set(x_10, 0, x_36);
return x_10;
}
else
{
lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_37 = lean_ctor_get(x_10, 1);
lean_inc(x_37);
lean_dec(x_10);
x_38 = lean_ctor_get(x_18, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_18, 1);
lean_inc(x_39);
lean_dec(x_18);
x_40 = lean_unsigned_to_nat(2u);
x_41 = lean_nat_pow(x_40, x_38);
lean_dec(x_38);
x_42 = l_Lean_mkRawNatLit(x_39);
lean_inc(x_41);
x_43 = l_Lean_mkNatLit(x_41);
x_44 = l_BitVec_reduceBitVecToFin___lambda__1___closed__6;
x_45 = l_Lean_Expr_app___override(x_44, x_43);
x_46 = lean_unsigned_to_nat(1u);
x_47 = lean_nat_sub(x_41, x_46);
lean_dec(x_41);
x_48 = l_Lean_mkNatLit(x_47);
x_49 = l_BitVec_reduceBitVecToFin___lambda__1___closed__9;
lean_inc(x_42);
x_50 = l_Lean_mkAppB(x_49, x_48, x_42);
x_51 = l_BitVec_reduceBitVecToFin___lambda__1___closed__3;
x_52 = l_Lean_mkApp3(x_51, x_45, x_42, x_50);
x_53 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_53, 0, x_52);
x_54 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_54, 0, x_53);
lean_ctor_set(x_54, 1, x_37);
return x_54;
}
}
}
else
{
uint8_t x_55; 
x_55 = !lean_is_exclusive(x_10);
if (x_55 == 0)
{
return x_10;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_10, 0);
x_57 = lean_ctor_get(x_10, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_10);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceBitVecToFin___lambda__1___boxed), 9, 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("toFin", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBitVecToFin___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceBitVecToFin___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; uint8_t x_16; 
x_10 = l_Lean_Meta_instantiateMVarsIfMVarApp(x_1, x_5, x_6, x_7, x_8, x_9);
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
x_12 = lean_ctor_get(x_10, 1);
lean_inc(x_12);
lean_dec(x_10);
x_13 = l_BitVec_reduceBitVecToFin___closed__1;
x_14 = l_BitVec_reduceAppend___closed__2;
x_15 = l_Lean_Expr_cleanupAnnotations(x_11);
x_16 = l_Lean_Expr_isApp(x_15);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
lean_dec(x_15);
x_17 = lean_box(0);
x_18 = lean_apply_9(x_14, x_17, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_18;
}
else
{
lean_object* x_19; lean_object* x_20; uint8_t x_21; 
x_19 = l_Lean_Expr_appArg(x_15, lean_box(0));
x_20 = l_Lean_Expr_appFnCleanup(x_15, lean_box(0));
x_21 = l_Lean_Expr_isApp(x_20);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; 
lean_dec(x_20);
lean_dec(x_19);
x_22 = lean_box(0);
x_23 = lean_apply_9(x_14, x_22, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_23;
}
else
{
lean_object* x_24; lean_object* x_25; uint8_t x_26; 
x_24 = l_Lean_Expr_appFnCleanup(x_20, lean_box(0));
x_25 = l_BitVec_reduceBitVecToFin___closed__3;
x_26 = l_Lean_Expr_isConstOf(x_24, x_25);
lean_dec(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
lean_dec(x_19);
x_27 = lean_box(0);
x_28 = lean_apply_9(x_14, x_27, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_28;
}
else
{
lean_object* x_29; 
x_29 = lean_apply_9(x_13, x_19, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_12);
return x_29;
}
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBitVecToFin___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceBitVecToFin___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceBitVecToFin", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__4;
x_2 = lean_unsigned_to_nat(0u);
x_3 = lean_alloc_ctor(6, 3, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
lean_ctor_set(x_3, 2, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__4;
x_2 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__6() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceBitVecToFin), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__2;
x_3 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__5;
x_4 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__6;
x_5 = l_Lean_Meta_Simp_registerBuiltinDSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685____closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__6;
x_2 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2;
x_3 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5687_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1;
x_3 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685____closed__1;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
lean_object* initialize_Lean_Meta_LitValues(uint8_t builtin, lean_object*);
lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Nat(uint8_t builtin, lean_object*);
lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Int(uint8_t builtin, lean_object*);
lean_object* initialize_Init_Data_BitVec_Basic(uint8_t builtin, lean_object*);
static bool _G_initialized = false;
LEAN_EXPORT lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec(uint8_t builtin, lean_object* w) {
lean_object * res;
if (_G_initialized) return lean_io_result_mk_ok(lean_box(0));
_G_initialized = true;
res = initialize_Lean_Meta_LitValues(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Nat(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Int(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Init_Data_BitVec_Basic(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
l_BitVec_reduceUnary___lambda__1___closed__1 = _init_l_BitVec_reduceUnary___lambda__1___closed__1();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__1);
l_BitVec_reduceUnary___lambda__1___closed__2 = _init_l_BitVec_reduceUnary___lambda__1___closed__2();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__2);
l_BitVec_reduceUnary___lambda__1___closed__3 = _init_l_BitVec_reduceUnary___lambda__1___closed__3();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__3);
l_BitVec_reduceUnary___lambda__1___closed__4 = _init_l_BitVec_reduceUnary___lambda__1___closed__4();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__4);
l_BitVec_reduceUnary___lambda__1___closed__5 = _init_l_BitVec_reduceUnary___lambda__1___closed__5();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__5);
l_BitVec_reduceGetBit___lambda__1___closed__1 = _init_l_BitVec_reduceGetBit___lambda__1___closed__1();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__1);
l_BitVec_reduceGetBit___lambda__1___closed__2 = _init_l_BitVec_reduceGetBit___lambda__1___closed__2();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__2);
l_BitVec_reduceGetBit___lambda__1___closed__3 = _init_l_BitVec_reduceGetBit___lambda__1___closed__3();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__3);
l_BitVec_reduceGetBit___lambda__1___closed__4 = _init_l_BitVec_reduceGetBit___lambda__1___closed__4();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__4);
l_BitVec_reduceGetBit___lambda__1___closed__5 = _init_l_BitVec_reduceGetBit___lambda__1___closed__5();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__5);
l_BitVec_reduceGetBit___lambda__1___closed__6 = _init_l_BitVec_reduceGetBit___lambda__1___closed__6();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__6);
l_BitVec_reduceGetBit___lambda__1___closed__7 = _init_l_BitVec_reduceGetBit___lambda__1___closed__7();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__7);
l_BitVec_reduceGetBit___lambda__1___closed__8 = _init_l_BitVec_reduceGetBit___lambda__1___closed__8();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__8);
l_BitVec_reduceGetBit___lambda__1___closed__9 = _init_l_BitVec_reduceGetBit___lambda__1___closed__9();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__9);
l_BitVec_reduceBinPred___lambda__1___closed__1 = _init_l_BitVec_reduceBinPred___lambda__1___closed__1();
lean_mark_persistent(l_BitVec_reduceBinPred___lambda__1___closed__1);
l_BitVec_reduceNeg___closed__1 = _init_l_BitVec_reduceNeg___closed__1();
lean_mark_persistent(l_BitVec_reduceNeg___closed__1);
l_BitVec_reduceNeg___closed__2 = _init_l_BitVec_reduceNeg___closed__2();
lean_mark_persistent(l_BitVec_reduceNeg___closed__2);
l_BitVec_reduceNeg___closed__3 = _init_l_BitVec_reduceNeg___closed__3();
lean_mark_persistent(l_BitVec_reduceNeg___closed__3);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__1 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__1);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__2 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__2);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__3 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__3);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__4 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__4);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__5);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__6);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__7 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__7);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__8 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__8);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__9 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__9);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__10 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__10);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__11 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__11);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__12 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194____closed__12);
if (builtin) {res = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1194_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__1 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__1);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196____closed__2);
if (builtin) {res = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1196_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1198_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceNot___closed__1 = _init_l_BitVec_reduceNot___closed__1();
lean_mark_persistent(l_BitVec_reduceNot___closed__1);
l_BitVec_reduceNot___closed__2 = _init_l_BitVec_reduceNot___closed__2();
lean_mark_persistent(l_BitVec_reduceNot___closed__2);
l_BitVec_reduceNot___closed__3 = _init_l_BitVec_reduceNot___closed__3();
lean_mark_persistent(l_BitVec_reduceNot___closed__3);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__1 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__1);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__2 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__2);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__3 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__3);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__4 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__4);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__5 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__5);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__6 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__6);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__7 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__7);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__8 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__8);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__9 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1231_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233____closed__1 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1233_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1235_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAbs___closed__1 = _init_l_BitVec_reduceAbs___closed__1();
lean_mark_persistent(l_BitVec_reduceAbs___closed__1);
l_BitVec_reduceAbs___closed__2 = _init_l_BitVec_reduceAbs___closed__2();
lean_mark_persistent(l_BitVec_reduceAbs___closed__2);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__1 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__1);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__2 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__2);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__3 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__3);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__4);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__5 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__5);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__6 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__6);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__7 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__7);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__8 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254____closed__1 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1254_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1256_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAnd___closed__1 = _init_l_BitVec_reduceAnd___closed__1();
lean_mark_persistent(l_BitVec_reduceAnd___closed__1);
l_BitVec_reduceAnd___closed__2 = _init_l_BitVec_reduceAnd___closed__2();
lean_mark_persistent(l_BitVec_reduceAnd___closed__2);
l_BitVec_reduceAnd___closed__3 = _init_l_BitVec_reduceAnd___closed__3();
lean_mark_persistent(l_BitVec_reduceAnd___closed__3);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__1 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__1);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__2 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__2);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__3 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__3);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__4);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__5 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__5);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__6 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__6);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__7 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__7);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__8 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__8);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__9 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__9);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__10 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__10);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__11 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__11);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__12 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__12);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__13 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__13);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__14 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__14);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__15 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__15();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294____closed__15);
if (builtin) {res = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296____closed__1 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1296_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1298_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOr___closed__1 = _init_l_BitVec_reduceOr___closed__1();
lean_mark_persistent(l_BitVec_reduceOr___closed__1);
l_BitVec_reduceOr___closed__2 = _init_l_BitVec_reduceOr___closed__2();
lean_mark_persistent(l_BitVec_reduceOr___closed__2);
l_BitVec_reduceOr___closed__3 = _init_l_BitVec_reduceOr___closed__3();
lean_mark_persistent(l_BitVec_reduceOr___closed__3);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__1 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__1);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__2 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__2);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__3 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__3);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__4 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__4);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__5 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__5);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__6 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__6);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__7 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__7);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__8 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__8);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__9 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__9);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__10 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__10);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__11 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__11);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__12 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__12);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__13 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__13);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__14 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338____closed__1 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1338_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1340_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceXOr___closed__1 = _init_l_BitVec_reduceXOr___closed__1();
lean_mark_persistent(l_BitVec_reduceXOr___closed__1);
l_BitVec_reduceXOr___closed__2 = _init_l_BitVec_reduceXOr___closed__2();
lean_mark_persistent(l_BitVec_reduceXOr___closed__2);
l_BitVec_reduceXOr___closed__3 = _init_l_BitVec_reduceXOr___closed__3();
lean_mark_persistent(l_BitVec_reduceXOr___closed__3);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__1 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__1);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__2 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__2);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__3 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__3);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__4 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__4);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__5 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__5);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__6 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__6);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__7 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__7);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__8 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__8);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__9 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__9);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__10 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__10);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__11 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__11);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__12 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__12);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__13 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__13);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__14 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380____closed__1 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1380_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1382_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAdd___closed__1 = _init_l_BitVec_reduceAdd___closed__1();
lean_mark_persistent(l_BitVec_reduceAdd___closed__1);
l_BitVec_reduceAdd___closed__2 = _init_l_BitVec_reduceAdd___closed__2();
lean_mark_persistent(l_BitVec_reduceAdd___closed__2);
l_BitVec_reduceAdd___closed__3 = _init_l_BitVec_reduceAdd___closed__3();
lean_mark_persistent(l_BitVec_reduceAdd___closed__3);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__1 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__1);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__2 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__2);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__3 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__3);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__4 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__4);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__5 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__5);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__6 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__6);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__7 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__7);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__8 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__8);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__9 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__9);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__10 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__10);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__11 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__11);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__12 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__12);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__13 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__13);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__14 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422____closed__1 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1422_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1424_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceMul___closed__1 = _init_l_BitVec_reduceMul___closed__1();
lean_mark_persistent(l_BitVec_reduceMul___closed__1);
l_BitVec_reduceMul___closed__2 = _init_l_BitVec_reduceMul___closed__2();
lean_mark_persistent(l_BitVec_reduceMul___closed__2);
l_BitVec_reduceMul___closed__3 = _init_l_BitVec_reduceMul___closed__3();
lean_mark_persistent(l_BitVec_reduceMul___closed__3);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__1 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__1);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__2 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__2);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__3 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__3);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__4 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__4);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__5 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__5);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__6 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__6);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__7 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__7);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__8 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__8);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__9 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__9);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__10 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__10);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__11 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__11);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__12 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__12);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__13 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__13);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__14 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464____closed__1 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1464_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1466_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSub___closed__1 = _init_l_BitVec_reduceSub___closed__1();
lean_mark_persistent(l_BitVec_reduceSub___closed__1);
l_BitVec_reduceSub___closed__2 = _init_l_BitVec_reduceSub___closed__2();
lean_mark_persistent(l_BitVec_reduceSub___closed__2);
l_BitVec_reduceSub___closed__3 = _init_l_BitVec_reduceSub___closed__3();
lean_mark_persistent(l_BitVec_reduceSub___closed__3);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__1 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__1);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__2 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__2);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__3 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__3);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__4 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__4);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__5 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__5);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__6 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__6);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__7 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__7);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__8 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__8);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__9 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__9);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__10 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__10);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__11 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__11);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__12 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__12);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__13 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__13);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__14 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506____closed__1 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1506_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1508_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceDiv___closed__1 = _init_l_BitVec_reduceDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceDiv___closed__1);
l_BitVec_reduceDiv___closed__2 = _init_l_BitVec_reduceDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceDiv___closed__2);
l_BitVec_reduceDiv___closed__3 = _init_l_BitVec_reduceDiv___closed__3();
lean_mark_persistent(l_BitVec_reduceDiv___closed__3);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__1 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__1);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__2 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__2);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__3 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__3);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__4 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__4);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__5 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__5);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__6 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__6);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__7 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__7);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__8 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__8);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__9 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__9);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__10 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__10);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__11 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__11);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__12 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__12);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__13 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__13);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__14 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548____closed__1 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1548_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1550_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceMod___closed__1 = _init_l_BitVec_reduceMod___closed__1();
lean_mark_persistent(l_BitVec_reduceMod___closed__1);
l_BitVec_reduceMod___closed__2 = _init_l_BitVec_reduceMod___closed__2();
lean_mark_persistent(l_BitVec_reduceMod___closed__2);
l_BitVec_reduceMod___closed__3 = _init_l_BitVec_reduceMod___closed__3();
lean_mark_persistent(l_BitVec_reduceMod___closed__3);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__1 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__1);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__2 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__2);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__3 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__3);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__4 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__4);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__5 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__5);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__6 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__6);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__7 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__7);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__8 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__8);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__9 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__9);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__10 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__10);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__11 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__11);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__12 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__12);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__13 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__13);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__14 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1588_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590____closed__1 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1590_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1592_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUMod___closed__1 = _init_l_BitVec_reduceUMod___closed__1();
lean_mark_persistent(l_BitVec_reduceUMod___closed__1);
l_BitVec_reduceUMod___closed__2 = _init_l_BitVec_reduceUMod___closed__2();
lean_mark_persistent(l_BitVec_reduceUMod___closed__2);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__1 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__1);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__2 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__2);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__3 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__3);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__4);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__5 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__5);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__6 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__6);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__7 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__7);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__8 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__8);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__9 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1614_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616____closed__1 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1616_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1618_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUDiv___closed__1 = _init_l_BitVec_reduceUDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceUDiv___closed__1);
l_BitVec_reduceUDiv___closed__2 = _init_l_BitVec_reduceUDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceUDiv___closed__2);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__1 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__1);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__2 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__2);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__3 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__3);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__4 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__4);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__5 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__5);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__6 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__6);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__7 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__7);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__8 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1640_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642____closed__1 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1642_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1644_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMTUDiv___closed__1 = _init_l_BitVec_reduceSMTUDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceSMTUDiv___closed__1);
l_BitVec_reduceSMTUDiv___closed__2 = _init_l_BitVec_reduceSMTUDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceSMTUDiv___closed__2);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__1 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__1);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__2 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__2);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__3 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__3);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__4 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__4);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__5 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__5);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__6 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__6);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__7 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__7);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__8 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1666_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668____closed__1 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1668_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1670_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMod___closed__1 = _init_l_BitVec_reduceSMod___closed__1();
lean_mark_persistent(l_BitVec_reduceSMod___closed__1);
l_BitVec_reduceSMod___closed__2 = _init_l_BitVec_reduceSMod___closed__2();
lean_mark_persistent(l_BitVec_reduceSMod___closed__2);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__1 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__1);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__2 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__2);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__3 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__3);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__4 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__4);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__5 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__5);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__6 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__6);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__7 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__7);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__8 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1692_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694____closed__1 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1694_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1696_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSRem___closed__1 = _init_l_BitVec_reduceSRem___closed__1();
lean_mark_persistent(l_BitVec_reduceSRem___closed__1);
l_BitVec_reduceSRem___closed__2 = _init_l_BitVec_reduceSRem___closed__2();
lean_mark_persistent(l_BitVec_reduceSRem___closed__2);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__1 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__1);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__2 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__2);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__3 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__3);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__4 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__4);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__5 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__5);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__6 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__6);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__7 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__7);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__8 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1718_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720____closed__1 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1720_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1722_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSDiv___closed__1 = _init_l_BitVec_reduceSDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceSDiv___closed__1);
l_BitVec_reduceSDiv___closed__2 = _init_l_BitVec_reduceSDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceSDiv___closed__2);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__1 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__1);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__2 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__2);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__3 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__3);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__4 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__4);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__5 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__5);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__6 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__6);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__7 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__7);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__8 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1744_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746____closed__1 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1746_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1748_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMTSDiv___closed__1 = _init_l_BitVec_reduceSMTSDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceSMTSDiv___closed__1);
l_BitVec_reduceSMTSDiv___closed__2 = _init_l_BitVec_reduceSMTSDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceSMTSDiv___closed__2);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__1 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__1);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__2 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__2);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__3 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__3);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__4 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__4);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__5 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__5);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__6 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__6);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__7 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__7);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__8 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772____closed__1 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1772_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1774_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetLsb___closed__1 = _init_l_BitVec_reduceGetLsb___closed__1();
lean_mark_persistent(l_BitVec_reduceGetLsb___closed__1);
l_BitVec_reduceGetLsb___closed__2 = _init_l_BitVec_reduceGetLsb___closed__2();
lean_mark_persistent(l_BitVec_reduceGetLsb___closed__2);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__1 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__1);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__2 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__2);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__3 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__3);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__4 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__4);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__5 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__5);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__6 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__6);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__7 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__7);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__8 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1791_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793____closed__1 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1793_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1795_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetMsb___closed__1 = _init_l_BitVec_reduceGetMsb___closed__1();
lean_mark_persistent(l_BitVec_reduceGetMsb___closed__1);
l_BitVec_reduceGetMsb___closed__2 = _init_l_BitVec_reduceGetMsb___closed__2();
lean_mark_persistent(l_BitVec_reduceGetMsb___closed__2);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__1 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__1);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__2 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__2);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__3 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__3);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__4 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__4);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__5 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__5);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__6 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__6);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__7 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__7);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__8 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814____closed__1 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1816_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeft___closed__1 = _init_l_BitVec_reduceShiftLeft___closed__1();
lean_mark_persistent(l_BitVec_reduceShiftLeft___closed__1);
l_BitVec_reduceShiftLeft___closed__2 = _init_l_BitVec_reduceShiftLeft___closed__2();
lean_mark_persistent(l_BitVec_reduceShiftLeft___closed__2);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__1 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__1);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__2 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__2);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__3 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__3);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__4 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__4);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__5 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__5);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__6 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__6);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__7 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__7);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__8 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836____closed__1 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1838_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUShiftRight___closed__1 = _init_l_BitVec_reduceUShiftRight___closed__1();
lean_mark_persistent(l_BitVec_reduceUShiftRight___closed__1);
l_BitVec_reduceUShiftRight___closed__2 = _init_l_BitVec_reduceUShiftRight___closed__2();
lean_mark_persistent(l_BitVec_reduceUShiftRight___closed__2);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__1 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__1);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__2 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__2);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__3 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__3);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__4 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__4);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__5 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__5);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__6 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__6);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__7 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__7);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__8 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1856_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858____closed__1 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1858_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1860_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSShiftRight___closed__1 = _init_l_BitVec_reduceSShiftRight___closed__1();
lean_mark_persistent(l_BitVec_reduceSShiftRight___closed__1);
l_BitVec_reduceSShiftRight___closed__2 = _init_l_BitVec_reduceSShiftRight___closed__2();
lean_mark_persistent(l_BitVec_reduceSShiftRight___closed__2);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__1 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__1);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__2 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__2);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__3 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__3);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__4 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__4);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__5 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__5);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__6 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__6);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__7 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__7);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__8 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880____closed__1 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1880_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1882_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftLeft___closed__1 = _init_l_BitVec_reduceHShiftLeft___closed__1();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___closed__1);
l_BitVec_reduceHShiftLeft___closed__2 = _init_l_BitVec_reduceHShiftLeft___closed__2();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___closed__2);
l_BitVec_reduceHShiftLeft___closed__3 = _init_l_BitVec_reduceHShiftLeft___closed__3();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___closed__3);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__1 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__1);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__2 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__2);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__3 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__3);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__4 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__4);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__5 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__5);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__6 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__6);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__7 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__7);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__8 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__8);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__9 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__9);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__10 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__10);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__11 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__11);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__12 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__12);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__13 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920____closed__13);
if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922____closed__1 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1922_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1924_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftRight___closed__1 = _init_l_BitVec_reduceHShiftRight___closed__1();
lean_mark_persistent(l_BitVec_reduceHShiftRight___closed__1);
l_BitVec_reduceHShiftRight___closed__2 = _init_l_BitVec_reduceHShiftRight___closed__2();
lean_mark_persistent(l_BitVec_reduceHShiftRight___closed__2);
l_BitVec_reduceHShiftRight___closed__3 = _init_l_BitVec_reduceHShiftRight___closed__3();
lean_mark_persistent(l_BitVec_reduceHShiftRight___closed__3);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__1 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__1);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__2 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__2);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__3 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__3);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__4 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__4);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__5 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__5);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__6 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__6);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__7 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__7);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__8 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__8);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__9 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__9);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__10 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__10);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__11 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__11);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__12 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962____closed__12);
if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964____closed__1 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1966_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceRotateLeft___closed__1 = _init_l_BitVec_reduceRotateLeft___closed__1();
lean_mark_persistent(l_BitVec_reduceRotateLeft___closed__1);
l_BitVec_reduceRotateLeft___closed__2 = _init_l_BitVec_reduceRotateLeft___closed__2();
lean_mark_persistent(l_BitVec_reduceRotateLeft___closed__2);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__1 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__1);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__2 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__2);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__3 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__3);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__4 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__4);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__5 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__5);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__6 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__6);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__7 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__7);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__8 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1984_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986____closed__1 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1986_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1988_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceRotateRight___closed__1 = _init_l_BitVec_reduceRotateRight___closed__1();
lean_mark_persistent(l_BitVec_reduceRotateRight___closed__1);
l_BitVec_reduceRotateRight___closed__2 = _init_l_BitVec_reduceRotateRight___closed__2();
lean_mark_persistent(l_BitVec_reduceRotateRight___closed__2);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__1 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__1);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__2 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__2);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__3 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__3);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__4 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__4);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__5 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__5);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__6 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__6);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__7 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__7);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__8 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2006_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008____closed__1 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2008_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2010_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAppend___closed__1 = _init_l_BitVec_reduceAppend___closed__1();
lean_mark_persistent(l_BitVec_reduceAppend___closed__1);
l_BitVec_reduceAppend___closed__2 = _init_l_BitVec_reduceAppend___closed__2();
lean_mark_persistent(l_BitVec_reduceAppend___closed__2);
l_BitVec_reduceAppend___closed__3 = _init_l_BitVec_reduceAppend___closed__3();
lean_mark_persistent(l_BitVec_reduceAppend___closed__3);
l_BitVec_reduceAppend___closed__4 = _init_l_BitVec_reduceAppend___closed__4();
lean_mark_persistent(l_BitVec_reduceAppend___closed__4);
l_BitVec_reduceAppend___closed__5 = _init_l_BitVec_reduceAppend___closed__5();
lean_mark_persistent(l_BitVec_reduceAppend___closed__5);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__1 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__1);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__2 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__2);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__3 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__3);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__4 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__4);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__5 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__5);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__6 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__6);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__7 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__7);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__8 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__8);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__9 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__9);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__10 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__10);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__11 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__11);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__12 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372____closed__12);
if (builtin) {res = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2372_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2376_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceCast___closed__1 = _init_l_BitVec_reduceCast___closed__1();
lean_mark_persistent(l_BitVec_reduceCast___closed__1);
l_BitVec_reduceCast___closed__2 = _init_l_BitVec_reduceCast___closed__2();
lean_mark_persistent(l_BitVec_reduceCast___closed__2);
l_BitVec_reduceCast___closed__3 = _init_l_BitVec_reduceCast___closed__3();
lean_mark_persistent(l_BitVec_reduceCast___closed__3);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__1 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__1);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__2 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__2);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__3 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__3);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__4 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__4);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__5 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__5);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__6 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__6);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__7 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__7);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__8 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__8);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__9 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2670_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672____closed__1 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2672_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2674_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceToNat___closed__1 = _init_l_BitVec_reduceToNat___closed__1();
lean_mark_persistent(l_BitVec_reduceToNat___closed__1);
l_BitVec_reduceToNat___closed__2 = _init_l_BitVec_reduceToNat___closed__2();
lean_mark_persistent(l_BitVec_reduceToNat___closed__2);
l_BitVec_reduceToNat___closed__3 = _init_l_BitVec_reduceToNat___closed__3();
lean_mark_persistent(l_BitVec_reduceToNat___closed__3);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__1 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__1);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__2 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__2);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__3 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__3);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__4 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__4);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__5 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__5);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__6 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__6);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__7 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2856_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858____closed__1 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2858_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2860_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceToInt___lambda__1___closed__1 = _init_l_BitVec_reduceToInt___lambda__1___closed__1();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__1);
l_BitVec_reduceToInt___lambda__1___closed__2 = _init_l_BitVec_reduceToInt___lambda__1___closed__2();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__2);
l_BitVec_reduceToInt___lambda__1___closed__3 = _init_l_BitVec_reduceToInt___lambda__1___closed__3();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__3);
l_BitVec_reduceToInt___lambda__1___closed__4 = _init_l_BitVec_reduceToInt___lambda__1___closed__4();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__4);
l_BitVec_reduceToInt___lambda__1___closed__5 = _init_l_BitVec_reduceToInt___lambda__1___closed__5();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__5);
l_BitVec_reduceToInt___lambda__1___closed__6 = _init_l_BitVec_reduceToInt___lambda__1___closed__6();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__6);
l_BitVec_reduceToInt___lambda__1___closed__7 = _init_l_BitVec_reduceToInt___lambda__1___closed__7();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__7);
l_BitVec_reduceToInt___lambda__1___closed__8 = _init_l_BitVec_reduceToInt___lambda__1___closed__8();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__8);
l_BitVec_reduceToInt___lambda__1___closed__9 = _init_l_BitVec_reduceToInt___lambda__1___closed__9();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__9);
l_BitVec_reduceToInt___lambda__1___closed__10 = _init_l_BitVec_reduceToInt___lambda__1___closed__10();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__10);
l_BitVec_reduceToInt___closed__1 = _init_l_BitVec_reduceToInt___closed__1();
lean_mark_persistent(l_BitVec_reduceToInt___closed__1);
l_BitVec_reduceToInt___closed__2 = _init_l_BitVec_reduceToInt___closed__2();
lean_mark_persistent(l_BitVec_reduceToInt___closed__2);
l_BitVec_reduceToInt___closed__3 = _init_l_BitVec_reduceToInt___closed__3();
lean_mark_persistent(l_BitVec_reduceToInt___closed__3);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__1 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__1);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__2 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__2);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__3 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__3);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__4 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__4);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__5 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__5);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__6 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__6);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__7 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3042_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044____closed__1 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3044_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3046_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOfInt___closed__1 = _init_l_BitVec_reduceOfInt___closed__1();
lean_mark_persistent(l_BitVec_reduceOfInt___closed__1);
l_BitVec_reduceOfInt___closed__2 = _init_l_BitVec_reduceOfInt___closed__2();
lean_mark_persistent(l_BitVec_reduceOfInt___closed__2);
l_BitVec_reduceOfInt___closed__3 = _init_l_BitVec_reduceOfInt___closed__3();
lean_mark_persistent(l_BitVec_reduceOfInt___closed__3);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__1 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__1);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__2 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__2);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__3 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__3);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__4 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__4);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__5 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__5);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__6 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__6);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__7 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3280_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282____closed__1 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3282_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3284_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOfNat___closed__1 = _init_l_BitVec_reduceOfNat___closed__1();
lean_mark_persistent(l_BitVec_reduceOfNat___closed__1);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__1 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__1);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__2 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__2);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__3 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__3);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__4 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__4);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__5 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__5);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__6 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__6);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__7 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3570_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572____closed__1 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3572_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3574_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceLT___closed__1 = _init_l_BitVec_reduceLT___closed__1();
lean_mark_persistent(l_BitVec_reduceLT___closed__1);
l_BitVec_reduceLT___closed__2 = _init_l_BitVec_reduceLT___closed__2();
lean_mark_persistent(l_BitVec_reduceLT___closed__2);
l_BitVec_reduceLT___closed__3 = _init_l_BitVec_reduceLT___closed__3();
lean_mark_persistent(l_BitVec_reduceLT___closed__3);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__1 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__1);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__2 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__2);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__3 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__3);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__4 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__4);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__5 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__5);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__6 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__6);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__7 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__7);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__8 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__8);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__9 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__9);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__10 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__10);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__11 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613____closed__11);
if (builtin) {res = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3613_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615____closed__1 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3615_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3617_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceLE___closed__1 = _init_l_BitVec_reduceLE___closed__1();
lean_mark_persistent(l_BitVec_reduceLE___closed__1);
l_BitVec_reduceLE___closed__2 = _init_l_BitVec_reduceLE___closed__2();
lean_mark_persistent(l_BitVec_reduceLE___closed__2);
l_BitVec_reduceLE___closed__3 = _init_l_BitVec_reduceLE___closed__3();
lean_mark_persistent(l_BitVec_reduceLE___closed__3);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__1 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__1);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__2 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__2);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__3 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__3);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__4 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__4);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__5 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__5);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__6 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__6);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__7 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__7);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__8 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__8);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__9 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__9);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__10 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656____closed__10);
if (builtin) {res = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3656_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658____closed__1 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3658_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3660_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGT___closed__1 = _init_l_BitVec_reduceGT___closed__1();
lean_mark_persistent(l_BitVec_reduceGT___closed__1);
l_BitVec_reduceGT___closed__2 = _init_l_BitVec_reduceGT___closed__2();
lean_mark_persistent(l_BitVec_reduceGT___closed__2);
l_BitVec_reduceGT___closed__3 = _init_l_BitVec_reduceGT___closed__3();
lean_mark_persistent(l_BitVec_reduceGT___closed__3);
l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__1 = _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__1);
l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__2 = _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__2);
l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__3 = _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699____closed__3);
if (builtin) {res = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3699_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701____closed__1 = _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3701_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3703_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGE___closed__1 = _init_l_BitVec_reduceGE___closed__1();
lean_mark_persistent(l_BitVec_reduceGE___closed__1);
l_BitVec_reduceGE___closed__2 = _init_l_BitVec_reduceGE___closed__2();
lean_mark_persistent(l_BitVec_reduceGE___closed__2);
l_BitVec_reduceGE___closed__3 = _init_l_BitVec_reduceGE___closed__3();
lean_mark_persistent(l_BitVec_reduceGE___closed__3);
l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__1 = _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__1);
l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__2 = _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__2);
l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__3 = _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742____closed__3);
if (builtin) {res = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3742_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744____closed__1 = _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3744_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3746_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceULT___closed__1 = _init_l_BitVec_reduceULT___closed__1();
lean_mark_persistent(l_BitVec_reduceULT___closed__1);
l_BitVec_reduceULT___closed__2 = _init_l_BitVec_reduceULT___closed__2();
lean_mark_persistent(l_BitVec_reduceULT___closed__2);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__1 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__1);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__2 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__2);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__3 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__3);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__4 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__4);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__5 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__5);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__6 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__6);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__7 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__7);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__8 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3764_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766____closed__1 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3766_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3768_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceULE___closed__1 = _init_l_BitVec_reduceULE___closed__1();
lean_mark_persistent(l_BitVec_reduceULE___closed__1);
l_BitVec_reduceULE___closed__2 = _init_l_BitVec_reduceULE___closed__2();
lean_mark_persistent(l_BitVec_reduceULE___closed__2);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__1 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__1);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__2 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__2);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__3 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__3);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__4 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__4);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__5 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__5);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__6 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__6);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__7 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__7);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__8 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3786_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788____closed__1 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3788_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSLT___closed__1 = _init_l_BitVec_reduceSLT___closed__1();
lean_mark_persistent(l_BitVec_reduceSLT___closed__1);
l_BitVec_reduceSLT___closed__2 = _init_l_BitVec_reduceSLT___closed__2();
lean_mark_persistent(l_BitVec_reduceSLT___closed__2);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__1 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__1);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__2 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__2);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__3 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__3);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__4 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__4);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__5 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__5);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__6 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__6);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__7 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__7);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__8 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3808_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810____closed__1 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3810_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3812_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSLE___closed__1 = _init_l_BitVec_reduceSLE___closed__1();
lean_mark_persistent(l_BitVec_reduceSLE___closed__1);
l_BitVec_reduceSLE___closed__2 = _init_l_BitVec_reduceSLE___closed__2();
lean_mark_persistent(l_BitVec_reduceSLE___closed__2);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__1 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__1);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__2 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__2);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__3 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__3);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__4 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__4);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__5 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__5);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__6 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__6);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__7 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__7);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__8 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3830_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832____closed__1 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3832_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3834_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceZeroExtend_x27___closed__1 = _init_l_BitVec_reduceZeroExtend_x27___closed__1();
lean_mark_persistent(l_BitVec_reduceZeroExtend_x27___closed__1);
l_BitVec_reduceZeroExtend_x27___closed__2 = _init_l_BitVec_reduceZeroExtend_x27___closed__2();
lean_mark_persistent(l_BitVec_reduceZeroExtend_x27___closed__2);
l_BitVec_reduceZeroExtend_x27___closed__3 = _init_l_BitVec_reduceZeroExtend_x27___closed__3();
lean_mark_persistent(l_BitVec_reduceZeroExtend_x27___closed__3);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__1 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__1);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__2 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__2);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__3 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__3);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__4 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__4);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__5 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__5);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__6 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__6);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__7 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__7);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__8 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__8);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__9 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4155_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157____closed__1 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4157_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4159_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeftZeroExtend___closed__1 = _init_l_BitVec_reduceShiftLeftZeroExtend___closed__1();
lean_mark_persistent(l_BitVec_reduceShiftLeftZeroExtend___closed__1);
l_BitVec_reduceShiftLeftZeroExtend___closed__2 = _init_l_BitVec_reduceShiftLeftZeroExtend___closed__2();
lean_mark_persistent(l_BitVec_reduceShiftLeftZeroExtend___closed__2);
l_BitVec_reduceShiftLeftZeroExtend___closed__3 = _init_l_BitVec_reduceShiftLeftZeroExtend___closed__3();
lean_mark_persistent(l_BitVec_reduceShiftLeftZeroExtend___closed__3);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__1 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__1);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__2 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__2);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__3 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__3);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__4 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__4);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__5 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__5);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__6 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__6);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__7 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__7);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__8 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4422_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424____closed__1 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4424_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4426_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceExtracLsb_x27___closed__1 = _init_l_BitVec_reduceExtracLsb_x27___closed__1();
lean_mark_persistent(l_BitVec_reduceExtracLsb_x27___closed__1);
l_BitVec_reduceExtracLsb_x27___closed__2 = _init_l_BitVec_reduceExtracLsb_x27___closed__2();
lean_mark_persistent(l_BitVec_reduceExtracLsb_x27___closed__2);
l_BitVec_reduceExtracLsb_x27___closed__3 = _init_l_BitVec_reduceExtracLsb_x27___closed__3();
lean_mark_persistent(l_BitVec_reduceExtracLsb_x27___closed__3);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__1 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__1);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__2 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__2);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__3 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__3);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__4 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__4);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__5 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__5);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__6 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__6);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__7 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__7);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__8 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__8);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__9 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4769_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771____closed__1 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4771_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_4773_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceReplicate___closed__1 = _init_l_BitVec_reduceReplicate___closed__1();
lean_mark_persistent(l_BitVec_reduceReplicate___closed__1);
l_BitVec_reduceReplicate___closed__2 = _init_l_BitVec_reduceReplicate___closed__2();
lean_mark_persistent(l_BitVec_reduceReplicate___closed__2);
l_BitVec_reduceReplicate___closed__3 = _init_l_BitVec_reduceReplicate___closed__3();
lean_mark_persistent(l_BitVec_reduceReplicate___closed__3);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__1 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__1);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__2 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__2);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__3 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__3);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__4 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__4);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__5 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__5);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__6 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__6);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__7 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__7);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__8 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5036_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038____closed__1 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5038_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5040_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceZeroExtend___closed__1 = _init_l_BitVec_reduceZeroExtend___closed__1();
lean_mark_persistent(l_BitVec_reduceZeroExtend___closed__1);
l_BitVec_reduceZeroExtend___closed__2 = _init_l_BitVec_reduceZeroExtend___closed__2();
lean_mark_persistent(l_BitVec_reduceZeroExtend___closed__2);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__1 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__1);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__2 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__2);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__3 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__3);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__4 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__4);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__5 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__5);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__6 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__6);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__7 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__7);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__8 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5057_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059____closed__1 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5059_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5061_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSignExtend___closed__1 = _init_l_BitVec_reduceSignExtend___closed__1();
lean_mark_persistent(l_BitVec_reduceSignExtend___closed__1);
l_BitVec_reduceSignExtend___closed__2 = _init_l_BitVec_reduceSignExtend___closed__2();
lean_mark_persistent(l_BitVec_reduceSignExtend___closed__2);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__1 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__1);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__2 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__2);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__3 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__3);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__4 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__4);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__5 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__5);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__6 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__6);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__7 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__7);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__8 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5078_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080____closed__1 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5080_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5082_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAllOnes___closed__1 = _init_l_BitVec_reduceAllOnes___closed__1();
lean_mark_persistent(l_BitVec_reduceAllOnes___closed__1);
l_BitVec_reduceAllOnes___closed__2 = _init_l_BitVec_reduceAllOnes___closed__2();
lean_mark_persistent(l_BitVec_reduceAllOnes___closed__2);
l_BitVec_reduceAllOnes___closed__3 = _init_l_BitVec_reduceAllOnes___closed__3();
lean_mark_persistent(l_BitVec_reduceAllOnes___closed__3);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__1 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__1);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__2 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__2);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__3 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__3);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__4 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__4);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__5 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__5);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__6 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__6);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__7 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5237_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239____closed__1 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5239_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5241_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBitVecOfFin___closed__1 = _init_l_BitVec_reduceBitVecOfFin___closed__1();
lean_mark_persistent(l_BitVec_reduceBitVecOfFin___closed__1);
l_BitVec_reduceBitVecOfFin___closed__2 = _init_l_BitVec_reduceBitVecOfFin___closed__2();
lean_mark_persistent(l_BitVec_reduceBitVecOfFin___closed__2);
l_BitVec_reduceBitVecOfFin___closed__3 = _init_l_BitVec_reduceBitVecOfFin___closed__3();
lean_mark_persistent(l_BitVec_reduceBitVecOfFin___closed__3);
l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__1 = _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__1);
l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__2 = _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__2);
l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__3 = _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__3);
l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__4 = _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__4);
l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__5 = _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__5);
l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__6 = _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__6);
l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__7 = _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5486_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488____closed__1 = _init_l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5488_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceBitVecOfFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5490_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceBitVecToFin___lambda__1___closed__1 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__1();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__1);
l_BitVec_reduceBitVecToFin___lambda__1___closed__2 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__2();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__2);
l_BitVec_reduceBitVecToFin___lambda__1___closed__3 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__3();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__3);
l_BitVec_reduceBitVecToFin___lambda__1___closed__4 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__4();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__4);
l_BitVec_reduceBitVecToFin___lambda__1___closed__5 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__5();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__5);
l_BitVec_reduceBitVecToFin___lambda__1___closed__6 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__6();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__6);
l_BitVec_reduceBitVecToFin___lambda__1___closed__7 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__7();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__7);
l_BitVec_reduceBitVecToFin___lambda__1___closed__8 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__8();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__8);
l_BitVec_reduceBitVecToFin___lambda__1___closed__9 = _init_l_BitVec_reduceBitVecToFin___lambda__1___closed__9();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___lambda__1___closed__9);
l_BitVec_reduceBitVecToFin___closed__1 = _init_l_BitVec_reduceBitVecToFin___closed__1();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___closed__1);
l_BitVec_reduceBitVecToFin___closed__2 = _init_l_BitVec_reduceBitVecToFin___closed__2();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___closed__2);
l_BitVec_reduceBitVecToFin___closed__3 = _init_l_BitVec_reduceBitVecToFin___closed__3();
lean_mark_persistent(l_BitVec_reduceBitVecToFin___closed__3);
l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__1 = _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__1);
l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__2 = _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__2);
l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__3 = _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__3);
l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__4 = _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__4);
l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__5 = _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__5);
l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__6 = _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683____closed__6);
if (builtin) {res = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5683_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685____closed__1 = _init_l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5685_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceBitVecToFin_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_5687_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}return lean_io_result_mk_ok(lean_box(0));
}
#ifdef __cplusplus
}
#endif
